{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"JDOT[Sucessful!].ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyNkybzHCCjnmpImjzIj9J9u"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","metadata":{"id":"dJQTvYiLS4ih"},"source":["Exceutable code from .py files"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4L-mF4vGRNTY","executionInfo":{"status":"ok","timestamp":1632037894197,"user_tz":-330,"elapsed":340,"user":{"displayName":"Ashly Ajith","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj6Mnqz-m77Vyo0dRpPQ4K1gFxZjJHFTiyYc55Pfg=s64","userId":"13073246282713666894"}},"outputId":"dec44843-af19-4599-fee5-437a9b090ec2"},"source":["%%writefile test.py\n","print(\"Hello world\")\n","a=2\n","print(a)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Writing test.py\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"TV4LxxUmSL6h","executionInfo":{"status":"ok","timestamp":1632037902067,"user_tz":-330,"elapsed":336,"user":{"displayName":"Ashly Ajith","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj6Mnqz-m77Vyo0dRpPQ4K1gFxZjJHFTiyYc55Pfg=s64","userId":"13073246282713666894"}},"outputId":"2fb4ec32-4973-4976-d1b7-de35cab68d40"},"source":["!python test.py"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Hello world\n","2\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2sRwodf2Sgr4","executionInfo":{"status":"ok","timestamp":1636891404761,"user_tz":-330,"elapsed":1439,"user":{"displayName":"Ashly Ajith","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj6Mnqz-m77Vyo0dRpPQ4K1gFxZjJHFTiyYc55Pfg=s64","userId":"13073246282713666894"}},"outputId":"d8cee8aa-6504-4fae-ff24-f567adec30b9"},"source":["!git clone https://github.com/bbdamodaran/deepJDOT.git"],"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Cloning into 'deepJDOT'...\n","remote: Enumerating objects: 191, done.\u001b[K\n","remote: Total 191 (delta 0), reused 0 (delta 0), pack-reused 191\u001b[K\n","Receiving objects: 100% (191/191), 64.75 KiB | 2.94 MiB/s, done.\n","Resolving deltas: 100% (105/105), done.\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"70GUksw3Soyh","executionInfo":{"status":"ok","timestamp":1634740065998,"user_tz":-330,"elapsed":537,"user":{"displayName":"Ashly Ajith","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj6Mnqz-m77Vyo0dRpPQ4K1gFxZjJHFTiyYc55Pfg=s64","userId":"13073246282713666894"}},"outputId":"5300dfbd-dc4e-4cd7-d85b-4266ac73ba44"},"source":["cd /content/deepJDOT/"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/deepJDOT\n"]}]},{"cell_type":"code","metadata":{"id":"zN66U8ZtUKLJ"},"source":["!python dnn.py"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"yb8aM7ZAPmWl"},"source":["#Code modification in Dnn !!\n","from keras import backend as K\n","from keras.models import Sequential, Model\n","from keras.layers import Dense, Activation, normalization, BatchNormalization\n","from keras.layers import Dropout,Flatten, Reshape, concatenate, GlobalAveragePooling2D\n","from keras.layers import Convolution2D, MaxPooling2D,UpSampling2D\n","from keras.utils import np_utils\n","from keras.layers import Input, Lambda\n","from tensorflow.keras.optimizers import SGD\n","#from keras.optimizers import SGD\n","import keras.callbacks\n","from keras.callbacks import ModelCheckpoint,EarlyStopping, LearningRateScheduler\n","from keras.models import model_from_json\n","from tensorflow.keras.layers import Layer, InputSpec\n","#from keras.engine.topology import Layer\n","#from keras.utils.visualize_util import plot\n","from keras.utils.np_utils import to_categorical\n","from keras.regularizers import l2\n","from keras.utils.np_utils import to_categorical\n","#from keras import objectives\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0Qil1PT1UchD","executionInfo":{"status":"ok","timestamp":1634739776888,"user_tz":-330,"elapsed":3890,"user":{"displayName":"Ashly Ajith","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj6Mnqz-m77Vyo0dRpPQ4K1gFxZjJHFTiyYc55Pfg=s64","userId":"13073246282713666894"}},"outputId":"a02f788c-cead-421f-9689-dcac0a7d9367"},"source":["pip install POT"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting POT\n","  Downloading POT-0.7.0-cp37-cp37m-manylinux2010_x86_64.whl (430 kB)\n","\u001b[?25l\r\u001b[K     |▊                               | 10 kB 33.9 MB/s eta 0:00:01\r\u001b[K     |█▌                              | 20 kB 19.4 MB/s eta 0:00:01\r\u001b[K     |██▎                             | 30 kB 16.0 MB/s eta 0:00:01\r\u001b[K     |███                             | 40 kB 14.6 MB/s eta 0:00:01\r\u001b[K     |███▉                            | 51 kB 7.5 MB/s eta 0:00:01\r\u001b[K     |████▋                           | 61 kB 7.2 MB/s eta 0:00:01\r\u001b[K     |█████▎                          | 71 kB 7.7 MB/s eta 0:00:01\r\u001b[K     |██████                          | 81 kB 8.6 MB/s eta 0:00:01\r\u001b[K     |██████▉                         | 92 kB 9.0 MB/s eta 0:00:01\r\u001b[K     |███████▋                        | 102 kB 7.2 MB/s eta 0:00:01\r\u001b[K     |████████▍                       | 112 kB 7.2 MB/s eta 0:00:01\r\u001b[K     |█████████▏                      | 122 kB 7.2 MB/s eta 0:00:01\r\u001b[K     |██████████                      | 133 kB 7.2 MB/s eta 0:00:01\r\u001b[K     |██████████▋                     | 143 kB 7.2 MB/s eta 0:00:01\r\u001b[K     |███████████▍                    | 153 kB 7.2 MB/s eta 0:00:01\r\u001b[K     |████████████▏                   | 163 kB 7.2 MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 174 kB 7.2 MB/s eta 0:00:01\r\u001b[K     |█████████████▊                  | 184 kB 7.2 MB/s eta 0:00:01\r\u001b[K     |██████████████▌                 | 194 kB 7.2 MB/s eta 0:00:01\r\u001b[K     |███████████████▏                | 204 kB 7.2 MB/s eta 0:00:01\r\u001b[K     |████████████████                | 215 kB 7.2 MB/s eta 0:00:01\r\u001b[K     |████████████████▊               | 225 kB 7.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████▌              | 235 kB 7.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████▎             | 245 kB 7.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 256 kB 7.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████▉            | 266 kB 7.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████▌           | 276 kB 7.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▎          | 286 kB 7.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 296 kB 7.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▉         | 307 kB 7.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▋        | 317 kB 7.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▍       | 327 kB 7.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 337 kB 7.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▉      | 348 kB 7.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▋     | 358 kB 7.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▍    | 368 kB 7.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▏   | 378 kB 7.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 389 kB 7.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▊  | 399 kB 7.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▍ | 409 kB 7.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▏| 419 kB 7.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 430 kB 7.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 430 kB 7.2 MB/s \n","\u001b[?25hRequirement already satisfied: scipy>=1.0 in /usr/local/lib/python3.7/dist-packages (from POT) (1.4.1)\n","Requirement already satisfied: numpy>=1.16 in /usr/local/lib/python3.7/dist-packages (from POT) (1.19.5)\n","Requirement already satisfied: cython>=0.23 in /usr/local/lib/python3.7/dist-packages (from POT) (0.29.24)\n","Installing collected packages: POT\n","Successfully installed POT-0.7.0\n"]}]},{"cell_type":"code","metadata":{"id":"u5dHBRIsUPXw"},"source":["import ot\n","!python Deepjdot.py"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"6prtpQIQQAGs"},"source":["#changes in da_dataload.py.py file!! Line 190\n","def svhnn_to_mnist(method = 'zero_mean_unitvarince', **params):\n","    from skimage.color import rgb2gray\n","    from skimage.transform import resize"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"X2tU9E_sOlVY","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1634740078463,"user_tz":-330,"elapsed":3977,"user":{"displayName":"Ashly Ajith","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj6Mnqz-m77Vyo0dRpPQ4K1gFxZjJHFTiyYc55Pfg=s64","userId":"13073246282713666894"}},"outputId":"8f8716de-143a-4979-9402-7c1e3c39089a"},"source":["#Download files to runtime  #SVHN\n","!wget http://ufldl.stanford.edu/housenumbers/train_32x32.mat\n","!wget http://ufldl.stanford.edu/housenumbers/test_32x32.mat"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["--2021-10-20 14:27:54--  http://ufldl.stanford.edu/housenumbers/train_32x32.mat\n","Resolving ufldl.stanford.edu (ufldl.stanford.edu)... 171.64.68.10\n","Connecting to ufldl.stanford.edu (ufldl.stanford.edu)|171.64.68.10|:80... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 182040794 (174M) [text/plain]\n","Saving to: ‘train_32x32.mat’\n","\n","train_32x32.mat     100%[===================>] 173.61M  68.6MB/s    in 2.5s    \n","\n","2021-10-20 14:27:56 (68.6 MB/s) - ‘train_32x32.mat’ saved [182040794/182040794]\n","\n","--2021-10-20 14:27:56--  http://ufldl.stanford.edu/housenumbers/test_32x32.mat\n","Resolving ufldl.stanford.edu (ufldl.stanford.edu)... 171.64.68.10\n","Connecting to ufldl.stanford.edu (ufldl.stanford.edu)|171.64.68.10|:80... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 64275384 (61M) [text/plain]\n","Saving to: ‘test_32x32.mat’\n","\n","test_32x32.mat      100%[===================>]  61.30M  57.5MB/s    in 1.1s    \n","\n","2021-10-20 14:27:58 (57.5 MB/s) - ‘test_32x32.mat’ saved [64275384/64275384]\n","\n"]}]},{"cell_type":"code","metadata":{"id":"IMlbuiau7KV0"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"nOyLS2-NDZyE"},"source":["mkdir data"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"LNwf6uL8F1WV","executionInfo":{"status":"ok","timestamp":1634739909207,"user_tz":-330,"elapsed":360,"user":{"displayName":"Ashly Ajith","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj6Mnqz-m77Vyo0dRpPQ4K1gFxZjJHFTiyYc55Pfg=s64","userId":"13073246282713666894"}},"outputId":"d042183b-952c-40e4-8377-52f52f62ee4c"},"source":["cd /content/deepJDOT/data"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/deepJDOT/data\n"]}]},{"cell_type":"code","metadata":{"id":"9KTYaHxOF7s_"},"source":["mkdir SVHN"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"SxL1WopMDiol"},"source":["#create -> data/ in deepJDOT -> SVHN/ and put in the files\n","!mv \"/content/deepJDOT/test_32x32.mat\" \"/content/deepJDOT/data/SVHN\"\n","!mv \"/content/deepJDOT/train_32x32.mat\" \"/content/deepJDOT/data/SVHN\""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"MWGxKKaNGm1E"},"source":["# After getting .mat file\n","## Datasetload.py  add file path in Line 235 "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"JlCfuBl1_-Yw"},"source":["# Preprocess.py Line 70\n","#from skimage.transform import resize\n","#line 84\n","#data1[i] = resize(data[i], (resize_size,resize_size))\n","\n","# deepjdot_svhn_mnist.py Line 21 add :\n","#import tensorflow as tf\n","#Line 147 add:\n","#optim = tf.optimizers.Adam(learning_rate=0.0002)\n","#Line 210 add:\n","#optim = tf.optimizers.Adam(learning_rate=0.0001)\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2Fe9toxzUqfg","executionInfo":{"status":"ok","timestamp":1634747177171,"user_tz":-330,"elapsed":6877703,"user":{"displayName":"Ashly Ajith","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj6Mnqz-m77Vyo0dRpPQ4K1gFxZjJHFTiyYc55Pfg=s64","userId":"13073246282713666894"}},"outputId":"bacab5f2-e8ca-488b-d16c-d9f29fdc4f03"},"source":["!python deepjdot_svhn_mnist.py"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["tcmalloc: large alloc 1800364032 bytes == 0x5594fbd5c000 @  0x7f1cc619a1e7 0x7f1cc3c5a46e 0x7f1cc3caac7b 0x7f1cc3caad18 0x7f1cc3d66d79 0x7f1cc3d69e4c 0x7f1cc3e88e7f 0x7f1cc3e8efb5 0x7f1cc3e90e3d 0x7f1cc3e92516 0x5594e3d1f720 0x5594e3d1f2f9 0x7f1cc3d714d8 0x5594e3d01933 0x5594e3e08496 0x5594e3d8f84a 0x5594e3d8c9ee 0x5594e3c5ee2b 0x5594e3d8efe4 0x5594e3d8c9ee 0x5594e3d1fbda 0x5594e3d8e737 0x5594e3d8c9ee 0x5594e3d8c6f3 0x5594e3e564c2 0x5594e3e5683d 0x5594e3e566e6 0x5594e3e2e163 0x5594e3e2de0c 0x7f1cc4f84bf7 0x5594e3e2dcea\n","Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n","11493376/11490434 [==============================] - 0s 0us/step\n","11501568/11490434 [==============================] - 0s 0us/step\n","tcmalloc: large alloc 1474560000 bytes == 0x5595d5150000 @  0x7f1cc619a1e7 0x7f1cc3c5a46e 0x7f1cc3caac7b 0x7f1cc3caad18 0x7f1cc3d52010 0x7f1cc3d5273c 0x7f1cc3d5285d 0x5594e3d20749 0x7f1cc3c97ef7 0x5594e3d1e437 0x5594e3d1e240 0x5594e3d91973 0x5594e3d8c9ee 0x5594e3d1fbda 0x5594e3d8e737 0x5594e3d8cced 0x5594e3c5ee2b 0x7f1cc3c97ef7 0x5594e3d1e437 0x5594e3d1e240 0x5594e3d91973 0x5594e3d8c9ee 0x5594e3d1fbda 0x5594e3d8e737 0x5594e3d8c9ee 0x5594e3d1fbda 0x5594e3d8e737 0x5594e3d8c9ee 0x5594e3d8c6f3 0x5594e3e564c2 0x5594e3e5683d\n","Do classification\n","2021-10-20 14:32:49.667257: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2021-10-20 14:32:49.877414: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2021-10-20 14:32:49.878081: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2021-10-20 14:32:49.879146: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2021-10-20 14:32:49.879761: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2021-10-20 14:32:49.880428: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2021-10-20 14:32:52.743808: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2021-10-20 14:32:52.744480: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2021-10-20 14:32:52.745093: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2021-10-20 14:32:52.745798: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n","2021-10-20 14:32:52.745855: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 15435 MB memory:  -> device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0\n","2021-10-20 14:32:54.371091: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n","Epoch 1/10\n","2021-10-20 14:32:56.196968: I tensorflow/stream_executor/cuda/cuda_dnn.cc:369] Loaded cuDNN version 8005\n","481/481 [==============================] - 31s 31ms/step - loss: 0.9214 - acc: 0.7072 - mae: 0.0852 - val_loss: 0.4844 - val_acc: 0.8638 - val_mae: 0.0497\n","Epoch 2/10\n","481/481 [==============================] - 14s 29ms/step - loss: 0.4355 - acc: 0.8738 - mae: 0.0438 - val_loss: 0.4065 - val_acc: 0.8824 - val_mae: 0.0410\n","Epoch 3/10\n","481/481 [==============================] - 14s 29ms/step - loss: 0.3504 - acc: 0.9000 - mae: 0.0355 - val_loss: 0.3472 - val_acc: 0.9004 - val_mae: 0.0336\n","Epoch 4/10\n","481/481 [==============================] - 14s 29ms/step - loss: 0.2955 - acc: 0.9167 - mae: 0.0302 - val_loss: 0.3226 - val_acc: 0.9063 - val_mae: 0.0311\n","Epoch 5/10\n","481/481 [==============================] - 14s 29ms/step - loss: 0.2476 - acc: 0.9313 - mae: 0.0259 - val_loss: 0.3073 - val_acc: 0.9098 - val_mae: 0.0284\n","Epoch 6/10\n","481/481 [==============================] - 14s 29ms/step - loss: 0.2100 - acc: 0.9436 - mae: 0.0225 - val_loss: 0.3006 - val_acc: 0.9135 - val_mae: 0.0269\n","Epoch 7/10\n","481/481 [==============================] - 14s 29ms/step - loss: 0.1748 - acc: 0.9552 - mae: 0.0193 - val_loss: 0.2970 - val_acc: 0.9144 - val_mae: 0.0258\n","Epoch 8/10\n","481/481 [==============================] - 14s 29ms/step - loss: 0.1439 - acc: 0.9653 - mae: 0.0163 - val_loss: 0.3031 - val_acc: 0.9120 - val_mae: 0.0260\n","Epoch 9/10\n","481/481 [==============================] - 14s 29ms/step - loss: 0.1173 - acc: 0.9745 - mae: 0.0137 - val_loss: 0.2875 - val_acc: 0.9164 - val_mae: 0.0237\n","Epoch 10/10\n","481/481 [==============================] - 14s 29ms/step - loss: 0.0936 - acc: 0.9813 - mae: 0.0113 - val_loss: 0.2901 - val_acc: 0.9178 - val_mae: 0.0229\n","2290/2290 [==============================] - 10s 4ms/step - loss: 0.1104 - acc: 0.9758 - mae: 0.0117\n","814/814 [==============================] - 4s 4ms/step - loss: 0.3258 - acc: 0.9048 - mae: 0.0261\n","1875/1875 [==============================] - 8s 4ms/step - loss: 3.4152 - acc: 0.1124 - mae: 0.1775\n","313/313 [==============================] - 1s 4ms/step - loss: 3.4027 - acc: 0.1135 - mae: 0.1772\n","metrics names: ['loss', 'acc', 'mae']\n","source train metrics using source model [0.1104203388094902, 0.9758248329162598, 0.011668522842228413]\n","target train metrics using source model [3.4152259826660156, 0.11236666887998581, 0.17752006649971008]\n","source test metrics using source model [0.32575488090515137, 0.9048094749450684, 0.0261040348559618]\n","target test metrics using source model [3.402745246887207, 0.11349999904632568, 0.17722073197364807]\n","iter = 0\n","[('loss', 0.14983108639717102), ('classifier_loss', 0.1166919395327568), ('fe_model_loss', 0.03313915431499481)]\n","313/313 [==============================] - 1s 3ms/step\n","Target acc: 0.1135\n","Target mae: 0.17701897\n","iter = 50\n","[('loss', 0.10775915533304214), ('classifier_loss', 0.08146443963050842), ('fe_model_loss', 0.02629471756517887)]\n","313/313 [==============================] - 1s 3ms/step\n","Target acc: 0.1789\n","Target mae: 0.17765404\n","iter = 100\n","[('loss', 0.11611390858888626), ('classifier_loss', 0.09081079065799713), ('fe_model_loss', 0.02530311606824398)]\n","313/313 [==============================] - 1s 3ms/step\n","Target acc: 0.1874\n","Target mae: 0.17726728\n","iter = 150\n","[('loss', 0.08106648176908493), ('classifier_loss', 0.05623000115156174), ('fe_model_loss', 0.024836480617523193)]\n","313/313 [==============================] - 1s 3ms/step\n","Target acc: 0.1664\n","Target mae: 0.1761231\n","iter = 200\n","[('loss', 0.09343523532152176), ('classifier_loss', 0.06895016878843307), ('fe_model_loss', 0.024485066533088684)]\n","313/313 [==============================] - 1s 3ms/step\n","Target acc: 0.1448\n","Target mae: 0.17566063\n","iter = 250\n","[('loss', 0.10388077795505524), ('classifier_loss', 0.07981222122907639), ('fe_model_loss', 0.024068553000688553)]\n","313/313 [==============================] - 1s 3ms/step\n","Target acc: 0.2553\n","Target mae: 0.17347458\n","iter = 300\n","[('loss', 0.11415039002895355), ('classifier_loss', 0.09064842760562897), ('fe_model_loss', 0.023501962423324585)]\n","313/313 [==============================] - 1s 3ms/step\n","Target acc: 0.2568\n","Target mae: 0.1717285\n","iter = 350\n","[('loss', 0.07250247150659561), ('classifier_loss', 0.049551233649253845), ('fe_model_loss', 0.022951237857341766)]\n","313/313 [==============================] - 1s 3ms/step\n","Target acc: 0.3039\n","Target mae: 0.1682583\n","iter = 400\n","[('loss', 0.10386382043361664), ('classifier_loss', 0.0817524716258049), ('fe_model_loss', 0.022111348807811737)]\n","313/313 [==============================] - 1s 3ms/step\n","Target acc: 0.3251\n","Target mae: 0.16471256\n","iter = 450\n","[('loss', 0.08521033078432083), ('classifier_loss', 0.06366076320409775), ('fe_model_loss', 0.021549569442868233)]\n","313/313 [==============================] - 1s 3ms/step\n","Target acc: 0.3205\n","Target mae: 0.16376898\n","iter = 500\n","[('loss', 0.07450436055660248), ('classifier_loss', 0.053472377359867096), ('fe_model_loss', 0.021031983196735382)]\n","313/313 [==============================] - 1s 3ms/step\n","Target acc: 0.3465\n","Target mae: 0.15991594\n","iter = 550\n","[('loss', 0.06161796301603317), ('classifier_loss', 0.04069312661886215), ('fe_model_loss', 0.02092483639717102)]\n","313/313 [==============================] - 1s 3ms/step\n","Target acc: 0.3389\n","Target mae: 0.16005501\n","iter = 600\n","[('loss', 0.08089262992143631), ('classifier_loss', 0.06091674417257309), ('fe_model_loss', 0.01997588761150837)]\n","313/313 [==============================] - 1s 3ms/step\n","Target acc: 0.3256\n","Target mae: 0.15655908\n","iter = 650\n","[('loss', 0.06475237011909485), ('classifier_loss', 0.04528149962425232), ('fe_model_loss', 0.01947086863219738)]\n","313/313 [==============================] - 1s 3ms/step\n","Target acc: 0.3505\n","Target mae: 0.15079376\n","iter = 700\n","[('loss', 0.06772781908512115), ('classifier_loss', 0.04870915040373802), ('fe_model_loss', 0.019018668681383133)]\n","313/313 [==============================] - 1s 3ms/step\n","Target acc: 0.3665\n","Target mae: 0.14762282\n","iter = 750\n","[('loss', 0.06311279535293579), ('classifier_loss', 0.04464990273118019), ('fe_model_loss', 0.01846289448440075)]\n","313/313 [==============================] - 1s 3ms/step\n","Target acc: 0.362\n","Target mae: 0.14475596\n","iter = 800\n","[('loss', 0.10072881728410721), ('classifier_loss', 0.08285406231880188), ('fe_model_loss', 0.01787475310266018)]\n","313/313 [==============================] - 1s 3ms/step\n","Target acc: 0.3788\n","Target mae: 0.14162417\n","iter = 850\n","[('loss', 0.06150670349597931), ('classifier_loss', 0.04364214465022087), ('fe_model_loss', 0.017864558845758438)]\n","313/313 [==============================] - 1s 3ms/step\n","Target acc: 0.3996\n","Target mae: 0.13790411\n","iter = 900\n","[('loss', 0.0596352182328701), ('classifier_loss', 0.04219505563378334), ('fe_model_loss', 0.01744016259908676)]\n","313/313 [==============================] - 1s 3ms/step\n","Target acc: 0.4114\n","Target mae: 0.13483368\n","iter = 950\n","[('loss', 0.0930091142654419), ('classifier_loss', 0.07586351782083511), ('fe_model_loss', 0.01714559644460678)]\n","313/313 [==============================] - 1s 3ms/step\n","Target acc: 0.3981\n","Target mae: 0.13431512\n","iter = 1000\n","[('loss', 0.053752556443214417), ('classifier_loss', 0.03702191263437271), ('fe_model_loss', 0.016730641946196556)]\n","313/313 [==============================] - 1s 3ms/step\n","Target acc: 0.4066\n","Target mae: 0.13235244\n","iter = 1050\n","[('loss', 0.07447554171085358), ('classifier_loss', 0.05770722031593323), ('fe_model_loss', 0.01676832139492035)]\n","313/313 [==============================] - 1s 3ms/step\n","Target acc: 0.3913\n","Target mae: 0.13346031\n","iter = 1100\n","[('loss', 0.06551691889762878), ('classifier_loss', 0.04869174584746361), ('fe_model_loss', 0.016825176775455475)]\n","313/313 [==============================] - 1s 3ms/step\n","Target acc: 0.3992\n","Target mae: 0.13155882\n","iter = 1150\n","[('loss', 0.03893318772315979), ('classifier_loss', 0.022862451151013374), ('fe_model_loss', 0.016070738434791565)]\n","313/313 [==============================] - 1s 3ms/step\n","Target acc: 0.3949\n","Target mae: 0.13121867\n","iter = 1200\n","[('loss', 0.059949737042188644), ('classifier_loss', 0.04386207088828087), ('fe_model_loss', 0.016087666153907776)]\n","313/313 [==============================] - 1s 3ms/step\n","Target acc: 0.4003\n","Target mae: 0.12993172\n","iter = 1250\n","[('loss', 0.043134089559316635), ('classifier_loss', 0.027148738503456116), ('fe_model_loss', 0.01598535105586052)]\n","313/313 [==============================] - 1s 3ms/step\n","Target acc: 0.3942\n","Target mae: 0.13026027\n","iter = 1300\n","[('loss', 0.06113208085298538), ('classifier_loss', 0.045431844890117645), ('fe_model_loss', 0.015700237825512886)]\n","313/313 [==============================] - 1s 3ms/step\n","Target acc: 0.3887\n","Target mae: 0.1307007\n","iter = 1350\n","[('loss', 0.04642227292060852), ('classifier_loss', 0.031103504821658134), ('fe_model_loss', 0.015318766236305237)]\n","313/313 [==============================] - 1s 3ms/step\n","Target acc: 0.3872\n","Target mae: 0.13037646\n","iter = 1400\n","[('loss', 0.04450962692499161), ('classifier_loss', 0.029142681509256363), ('fe_model_loss', 0.015366943553090096)]\n","313/313 [==============================] - 1s 3ms/step\n","Target acc: 0.3895\n","Target mae: 0.12963155\n","iter = 1450\n","[('loss', 0.05415033921599388), ('classifier_loss', 0.03896709159016609), ('fe_model_loss', 0.01518324762582779)]\n","313/313 [==============================] - 1s 3ms/step\n","Target acc: 0.3813\n","Target mae: 0.13061973\n","iter = 1500\n","[('loss', 0.057637348771095276), ('classifier_loss', 0.04279986768960953), ('fe_model_loss', 0.0148374754935503)]\n","313/313 [==============================] - 1s 3ms/step\n","Target acc: 0.3809\n","Target mae: 0.13045362\n","iter = 1550\n","[('loss', 0.05419344827532768), ('classifier_loss', 0.03980696201324463), ('fe_model_loss', 0.014386485330760479)]\n","313/313 [==============================] - 1s 3ms/step\n","Target acc: 0.3832\n","Target mae: 0.12958561\n","iter = 1600\n","[('loss', 0.0675911232829094), ('classifier_loss', 0.05285774543881416), ('fe_model_loss', 0.014733378775417805)]\n","313/313 [==============================] - 1s 3ms/step\n","Target acc: 0.3746\n","Target mae: 0.13077644\n","iter = 1650\n","[('loss', 0.05486162751913071), ('classifier_loss', 0.040637560188770294), ('fe_model_loss', 0.014224064536392689)]\n","313/313 [==============================] - 1s 3ms/step\n","Target acc: 0.3806\n","Target mae: 0.12989572\n","iter = 1700\n","[('loss', 0.05683347210288048), ('classifier_loss', 0.0426359698176384), ('fe_model_loss', 0.014197503216564655)]\n","313/313 [==============================] - 1s 3ms/step\n","Target acc: 0.3872\n","Target mae: 0.12814133\n","iter = 1750\n","[('loss', 0.047854289412498474), ('classifier_loss', 0.033870190382003784), ('fe_model_loss', 0.01398410089313984)]\n","313/313 [==============================] - 1s 3ms/step\n","Target acc: 0.3793\n","Target mae: 0.12929103\n","iter = 1800\n","[('loss', 0.05108688026666641), ('classifier_loss', 0.0369841568171978), ('fe_model_loss', 0.014102722518146038)]\n","313/313 [==============================] - 1s 3ms/step\n","Target acc: 0.3831\n","Target mae: 0.12812014\n","iter = 1850\n","[('loss', 0.042569030076265335), ('classifier_loss', 0.02884022518992424), ('fe_model_loss', 0.01372880581766367)]\n","313/313 [==============================] - 1s 3ms/step\n","Target acc: 0.3781\n","Target mae: 0.12905796\n","iter = 1900\n","[('loss', 0.10211081057786942), ('classifier_loss', 0.08892279863357544), ('fe_model_loss', 0.013188011944293976)]\n","313/313 [==============================] - 1s 3ms/step\n","Target acc: 0.3803\n","Target mae: 0.12865756\n","iter = 1950\n","[('loss', 0.02893516793847084), ('classifier_loss', 0.015336737036705017), ('fe_model_loss', 0.013598431833088398)]\n","313/313 [==============================] - 1s 3ms/step\n","Target acc: 0.3807\n","Target mae: 0.12822089\n","iter = 2000\n","[('loss', 0.055302392691373825), ('classifier_loss', 0.041872672736644745), ('fe_model_loss', 0.013429720886051655)]\n","313/313 [==============================] - 1s 3ms/step\n","Target acc: 0.3886\n","Target mae: 0.12676015\n","iter = 2050\n","[('loss', 0.04283380135893822), ('classifier_loss', 0.02965465746819973), ('fe_model_loss', 0.013179144822061062)]\n","313/313 [==============================] - 1s 3ms/step\n","Target acc: 0.3785\n","Target mae: 0.1282332\n","iter = 2100\n","[('loss', 0.04543810710310936), ('classifier_loss', 0.03267541527748108), ('fe_model_loss', 0.012762692756950855)]\n","313/313 [==============================] - 1s 3ms/step\n","Target acc: 0.376\n","Target mae: 0.128194\n","iter = 2150\n","[('loss', 0.043202612549066544), ('classifier_loss', 0.02993945963680744), ('fe_model_loss', 0.013263151980936527)]\n","313/313 [==============================] - 1s 3ms/step\n","Target acc: 0.3758\n","Target mae: 0.12871833\n","iter = 2200\n","[('loss', 0.05571596324443817), ('classifier_loss', 0.04286077991127968), ('fe_model_loss', 0.012855185195803642)]\n","313/313 [==============================] - 1s 3ms/step\n","Target acc: 0.3788\n","Target mae: 0.12765303\n","iter = 2250\n","[('loss', 0.04644592106342316), ('classifier_loss', 0.03409617766737938), ('fe_model_loss', 0.012349743396043777)]\n","313/313 [==============================] - 1s 3ms/step\n","Target acc: 0.3784\n","Target mae: 0.12774019\n","iter = 2300\n","[('loss', 0.022526953369379044), ('classifier_loss', 0.009698179550468922), ('fe_model_loss', 0.012828774750232697)]\n","313/313 [==============================] - 1s 3ms/step\n","Target acc: 0.3673\n","Target mae: 0.12952183\n","iter = 2350\n","[('loss', 0.03559490293264389), ('classifier_loss', 0.023269658908247948), ('fe_model_loss', 0.012325244024395943)]\n","313/313 [==============================] - 1s 3ms/step\n","Target acc: 0.3767\n","Target mae: 0.12744185\n","iter = 2400\n","[('loss', 0.07035412639379501), ('classifier_loss', 0.0580572634935379), ('fe_model_loss', 0.012296865694224834)]\n","313/313 [==============================] - 1s 3ms/step\n","Target acc: 0.3758\n","Target mae: 0.12808752\n","iter = 2450\n","[('loss', 0.06383493542671204), ('classifier_loss', 0.0516611710190773), ('fe_model_loss', 0.01217376347631216)]\n","313/313 [==============================] - 1s 3ms/step\n","Target acc: 0.3735\n","Target mae: 0.12801911\n","iter = 2500\n","[('loss', 0.027366451919078827), ('classifier_loss', 0.01523284800350666), ('fe_model_loss', 0.012133604846894741)]\n","313/313 [==============================] - 1s 3ms/step\n","Target acc: 0.3734\n","Target mae: 0.12789962\n","iter = 2550\n","[('loss', 0.05749448016285896), ('classifier_loss', 0.04540722444653511), ('fe_model_loss', 0.012087255716323853)]\n","313/313 [==============================] - 1s 3ms/step\n","Target acc: 0.379\n","Target mae: 0.12689525\n","iter = 2600\n","[('loss', 0.03737638518214226), ('classifier_loss', 0.02557000331580639), ('fe_model_loss', 0.011806380935013294)]\n","313/313 [==============================] - 1s 3ms/step\n","Target acc: 0.3766\n","Target mae: 0.12726\n","iter = 2650\n","[('loss', 0.022104069590568542), ('classifier_loss', 0.01045869942754507), ('fe_model_loss', 0.011645371094346046)]\n","313/313 [==============================] - 1s 3ms/step\n","Target acc: 0.3754\n","Target mae: 0.12722732\n","iter = 2700\n","[('loss', 0.030264802277088165), ('classifier_loss', 0.01851290464401245), ('fe_model_loss', 0.011751898564398289)]\n","313/313 [==============================] - 1s 3ms/step\n","Target acc: 0.3698\n","Target mae: 0.12817062\n","iter = 2750\n","[('loss', 0.06828074157238007), ('classifier_loss', 0.05694303289055824), ('fe_model_loss', 0.011337711475789547)]\n","313/313 [==============================] - 1s 3ms/step\n","Target acc: 0.369\n","Target mae: 0.12868977\n","iter = 2800\n","[('loss', 0.055828243494033813), ('classifier_loss', 0.04447159916162491), ('fe_model_loss', 0.011356642469763756)]\n","313/313 [==============================] - 1s 3ms/step\n","Target acc: 0.377\n","Target mae: 0.12712821\n","iter = 2850\n","[('loss', 0.04907551407814026), ('classifier_loss', 0.03779343515634537), ('fe_model_loss', 0.011282077990472317)]\n","313/313 [==============================] - 1s 3ms/step\n","Target acc: 0.3733\n","Target mae: 0.1275804\n","iter = 2900\n","[('loss', 0.024101339280605316), ('classifier_loss', 0.012632610276341438), ('fe_model_loss', 0.011468728072941303)]\n","313/313 [==============================] - 1s 3ms/step\n","Target acc: 0.3758\n","Target mae: 0.12715676\n","iter = 2950\n","[('loss', 0.04109843447804451), ('classifier_loss', 0.030180109664797783), ('fe_model_loss', 0.010918325744569302)]\n","313/313 [==============================] - 1s 3ms/step\n","Target acc: 0.3691\n","Target mae: 0.12841347\n","iter = 3000\n","[('loss', 0.0385846383869648), ('classifier_loss', 0.027277924120426178), ('fe_model_loss', 0.011306713335216045)]\n","313/313 [==============================] - 1s 3ms/step\n","Target acc: 0.3663\n","Target mae: 0.12881252\n","iter = 3050\n","[('loss', 0.03829430043697357), ('classifier_loss', 0.026923712342977524), ('fe_model_loss', 0.011370588093996048)]\n","313/313 [==============================] - 1s 3ms/step\n","Target acc: 0.3694\n","Target mae: 0.1284082\n","iter = 3100\n","[('loss', 0.022648943588137627), ('classifier_loss', 0.011772106401622295), ('fe_model_loss', 0.010876837186515331)]\n","313/313 [==============================] - 1s 3ms/step\n","Target acc: 0.3713\n","Target mae: 0.12769452\n","iter = 3150\n","[('loss', 0.03412965312600136), ('classifier_loss', 0.023209044709801674), ('fe_model_loss', 0.010920609347522259)]\n","313/313 [==============================] - 1s 3ms/step\n","Target acc: 0.3729\n","Target mae: 0.12737533\n","iter = 3200\n","[('loss', 0.030096741393208504), ('classifier_loss', 0.019063765183091164), ('fe_model_loss', 0.01103297621011734)]\n","313/313 [==============================] - 1s 3ms/step\n","Target acc: 0.3713\n","Target mae: 0.12753117\n","iter = 3250\n","[('loss', 0.0456034280359745), ('classifier_loss', 0.034369103610515594), ('fe_model_loss', 0.011234324425458908)]\n","313/313 [==============================] - 1s 3ms/step\n","Target acc: 0.3681\n","Target mae: 0.12832436\n","iter = 3300\n","[('loss', 0.04301336407661438), ('classifier_loss', 0.03198946639895439), ('fe_model_loss', 0.011023897677659988)]\n","313/313 [==============================] - 1s 3ms/step\n","Target acc: 0.3672\n","Target mae: 0.12845252\n","iter = 3350\n","[('loss', 0.04804166406393051), ('classifier_loss', 0.0375378355383873), ('fe_model_loss', 0.010503827594220638)]\n","313/313 [==============================] - 1s 3ms/step\n","Target acc: 0.3652\n","Target mae: 0.12860216\n","iter = 3400\n","[('loss', 0.019995873793959618), ('classifier_loss', 0.008854739367961884), ('fe_model_loss', 0.011141134425997734)]\n","313/313 [==============================] - 1s 3ms/step\n","Target acc: 0.3697\n","Target mae: 0.12765782\n","iter = 3450\n","[('loss', 0.025391340255737305), ('classifier_loss', 0.014934814535081387), ('fe_model_loss', 0.010456524789333344)]\n","313/313 [==============================] - 1s 3ms/step\n","Target acc: 0.3698\n","Target mae: 0.12808242\n","iter = 3500\n","[('loss', 0.03928578272461891), ('classifier_loss', 0.02901257574558258), ('fe_model_loss', 0.010273207910358906)]\n","313/313 [==============================] - 1s 3ms/step\n","Target acc: 0.37\n","Target mae: 0.1280466\n","iter = 3550\n","[('loss', 0.02285933867096901), ('classifier_loss', 0.01202821359038353), ('fe_model_loss', 0.010831124149262905)]\n","313/313 [==============================] - 1s 3ms/step\n","Target acc: 0.3668\n","Target mae: 0.12862617\n","iter = 3600\n","[('loss', 0.028915120288729668), ('classifier_loss', 0.018436316400766373), ('fe_model_loss', 0.010478803887963295)]\n","313/313 [==============================] - 1s 3ms/step\n","Target acc: 0.368\n","Target mae: 0.12807474\n","iter = 3650\n","[('loss', 0.05937496945261955), ('classifier_loss', 0.049187563359737396), ('fe_model_loss', 0.010187405161559582)]\n","313/313 [==============================] - 1s 3ms/step\n","Target acc: 0.3696\n","Target mae: 0.12781776\n","iter = 3700\n","[('loss', 0.03983376920223236), ('classifier_loss', 0.029670942574739456), ('fe_model_loss', 0.01016282569617033)]\n","313/313 [==============================] - 1s 3ms/step\n","Target acc: 0.3635\n","Target mae: 0.12920463\n","iter = 3750\n","[('loss', 0.036879703402519226), ('classifier_loss', 0.026695480570197105), ('fe_model_loss', 0.010184220969676971)]\n","313/313 [==============================] - 1s 3ms/step\n","Target acc: 0.3626\n","Target mae: 0.12897584\n","iter = 3800\n","[('loss', 0.04538417607545853), ('classifier_loss', 0.03516643866896629), ('fe_model_loss', 0.010217738337814808)]\n","313/313 [==============================] - 1s 3ms/step\n","Target acc: 0.3622\n","Target mae: 0.12925613\n","iter = 3850\n","[('loss', 0.031205635517835617), ('classifier_loss', 0.02108204923570156), ('fe_model_loss', 0.01012358721345663)]\n","313/313 [==============================] - 1s 3ms/step\n","Target acc: 0.3665\n","Target mae: 0.12809022\n","iter = 3900\n","[('loss', 0.028360888361930847), ('classifier_loss', 0.018415972590446472), ('fe_model_loss', 0.00994491670280695)]\n","313/313 [==============================] - 1s 3ms/step\n","Target acc: 0.3695\n","Target mae: 0.12785676\n","iter = 3950\n","[('loss', 0.01912691816687584), ('classifier_loss', 0.008959436789155006), ('fe_model_loss', 0.010167480446398258)]\n","313/313 [==============================] - 1s 3ms/step\n","Target acc: 0.3611\n","Target mae: 0.12944366\n","iter = 4000\n","[('loss', 0.017374014481902122), ('classifier_loss', 0.00800500437617302), ('fe_model_loss', 0.009369010105729103)]\n","313/313 [==============================] - 1s 3ms/step\n","Target acc: 0.3664\n","Target mae: 0.12811524\n","iter = 4050\n","[('loss', 0.03326057270169258), ('classifier_loss', 0.02317112125456333), ('fe_model_loss', 0.01008945144712925)]\n","313/313 [==============================] - 1s 3ms/step\n","Target acc: 0.3649\n","Target mae: 0.1287972\n","iter = 4100\n","[('loss', 0.038827113807201385), ('classifier_loss', 0.02907196618616581), ('fe_model_loss', 0.00975514855235815)]\n","313/313 [==============================] - 1s 3ms/step\n","Target acc: 0.362\n","Target mae: 0.12907435\n","iter = 4150\n","[('loss', 0.02994348295032978), ('classifier_loss', 0.019969169050455093), ('fe_model_loss', 0.009974313899874687)]\n","313/313 [==============================] - 1s 3ms/step\n","Target acc: 0.3566\n","Target mae: 0.12993097\n","iter = 4200\n","[('loss', 0.01966346800327301), ('classifier_loss', 0.010306124575436115), ('fe_model_loss', 0.00935734435915947)]\n","313/313 [==============================] - 1s 3ms/step\n","Target acc: 0.361\n","Target mae: 0.12913296\n","iter = 4250\n","[('loss', 0.04079227149486542), ('classifier_loss', 0.03125816583633423), ('fe_model_loss', 0.009534105658531189)]\n","313/313 [==============================] - 1s 3ms/step\n","Target acc: 0.3586\n","Target mae: 0.12974712\n","iter = 4300\n","[('loss', 0.024421773850917816), ('classifier_loss', 0.015244180336594582), ('fe_model_loss', 0.009177593514323235)]\n","313/313 [==============================] - 1s 3ms/step\n","Target acc: 0.3606\n","Target mae: 0.12927139\n","iter = 4350\n","[('loss', 0.023364918306469917), ('classifier_loss', 0.013849250040948391), ('fe_model_loss', 0.009515668265521526)]\n","313/313 [==============================] - 1s 3ms/step\n","Target acc: 0.3613\n","Target mae: 0.12922934\n","iter = 4400\n","[('loss', 0.03777201473712921), ('classifier_loss', 0.027943825349211693), ('fe_model_loss', 0.009828189387917519)]\n","313/313 [==============================] - 1s 3ms/step\n","Target acc: 0.3635\n","Target mae: 0.12866701\n","iter = 4450\n","[('loss', 0.0439194031059742), ('classifier_loss', 0.034570906311273575), ('fe_model_loss', 0.009348497726023197)]\n","313/313 [==============================] - 1s 3ms/step\n","Target acc: 0.3581\n","Target mae: 0.12955005\n","iter = 4500\n","[('loss', 0.015791170299053192), ('classifier_loss', 0.006056597921997309), ('fe_model_loss', 0.00973457284271717)]\n","313/313 [==============================] - 1s 3ms/step\n","Target acc: 0.3571\n","Target mae: 0.1297743\n","iter = 4550\n","[('loss', 0.029756082221865654), ('classifier_loss', 0.020504074171185493), ('fe_model_loss', 0.00925200805068016)]\n","313/313 [==============================] - 1s 3ms/step\n","Target acc: 0.3599\n","Target mae: 0.12923558\n","iter = 4600\n","[('loss', 0.06028050184249878), ('classifier_loss', 0.05054398626089096), ('fe_model_loss', 0.009736515581607819)]\n","313/313 [==============================] - 1s 3ms/step\n","Target acc: 0.3572\n","Target mae: 0.12989\n","iter = 4650\n","[('loss', 0.034213628619909286), ('classifier_loss', 0.024709679186344147), ('fe_model_loss', 0.009503950364887714)]\n","313/313 [==============================] - 1s 3ms/step\n","Target acc: 0.36\n","Target mae: 0.12906364\n","iter = 4700\n","[('loss', 0.038548871874809265), ('classifier_loss', 0.029100269079208374), ('fe_model_loss', 0.009448603726923466)]\n","313/313 [==============================] - 1s 3ms/step\n","Target acc: 0.3582\n","Target mae: 0.12944986\n","iter = 4750\n","[('loss', 0.024933572858572006), ('classifier_loss', 0.015640148892998695), ('fe_model_loss', 0.009293423034250736)]\n","313/313 [==============================] - 1s 3ms/step\n","Target acc: 0.3532\n","Target mae: 0.13053522\n","iter = 4800\n","[('loss', 0.06777666509151459), ('classifier_loss', 0.05878349393606186), ('fe_model_loss', 0.008993174880743027)]\n","313/313 [==============================] - 1s 3ms/step\n","Target acc: 0.3534\n","Target mae: 0.13022187\n","iter = 4850\n","[('loss', 0.04693866893649101), ('classifier_loss', 0.0379643440246582), ('fe_model_loss', 0.00897432491183281)]\n","313/313 [==============================] - 1s 3ms/step\n","Target acc: 0.358\n","Target mae: 0.12954769\n","iter = 4900\n","[('loss', 0.022488240152597427), ('classifier_loss', 0.013196639716625214), ('fe_model_loss', 0.009291601367294788)]\n","313/313 [==============================] - 1s 3ms/step\n","Target acc: 0.3574\n","Target mae: 0.12968878\n","iter = 4950\n","[('loss', 0.027383945882320404), ('classifier_loss', 0.01808137446641922), ('fe_model_loss', 0.00930257048457861)]\n","313/313 [==============================] - 1s 3ms/step\n","Target acc: 0.3553\n","Target mae: 0.13005453\n","iter = 5000\n","[('loss', 0.024920091032981873), ('classifier_loss', 0.01587073691189289), ('fe_model_loss', 0.009049355052411556)]\n","313/313 [==============================] - 1s 3ms/step\n","Target acc: 0.3617\n","Target mae: 0.12894346\n","iter = 5050\n","[('loss', 0.016883892938494682), ('classifier_loss', 0.0077913482673466206), ('fe_model_loss', 0.009092544205486774)]\n","313/313 [==============================] - 1s 3ms/step\n","Target acc: 0.3584\n","Target mae: 0.12940598\n","iter = 5100\n","[('loss', 0.031140681356191635), ('classifier_loss', 0.022336620837450027), ('fe_model_loss', 0.008804061450064182)]\n","313/313 [==============================] - 1s 3ms/step\n","Target acc: 0.3596\n","Target mae: 0.12938134\n","iter = 5150\n","[('loss', 0.022646360099315643), ('classifier_loss', 0.013881879858672619), ('fe_model_loss', 0.008764481171965599)]\n","313/313 [==============================] - 1s 3ms/step\n","Target acc: 0.3623\n","Target mae: 0.12877573\n","iter = 5200\n","[('loss', 0.020023290067911148), ('classifier_loss', 0.010848759673535824), ('fe_model_loss', 0.00917452946305275)]\n","313/313 [==============================] - 1s 3ms/step\n","Target acc: 0.3532\n","Target mae: 0.13022281\n","iter = 5250\n","[('loss', 0.028245480731129646), ('classifier_loss', 0.01930074207484722), ('fe_model_loss', 0.008944738656282425)]\n","313/313 [==============================] - 1s 3ms/step\n","Target acc: 0.3528\n","Target mae: 0.13038129\n","iter = 5300\n","[('loss', 0.0226890966296196), ('classifier_loss', 0.013790572062134743), ('fe_model_loss', 0.00889852549880743)]\n","313/313 [==============================] - 1s 3ms/step\n","Target acc: 0.3543\n","Target mae: 0.13030943\n","iter = 5350\n","[('loss', 0.04150862619280815), ('classifier_loss', 0.0326196551322937), ('fe_model_loss', 0.008888971991837025)]\n","313/313 [==============================] - 1s 3ms/step\n","Target acc: 0.3577\n","Target mae: 0.12947412\n","iter = 5400\n","[('loss', 0.019652556627988815), ('classifier_loss', 0.010924071073532104), ('fe_model_loss', 0.008728483691811562)]\n","313/313 [==============================] - 1s 3ms/step\n","Target acc: 0.3497\n","Target mae: 0.13096064\n","iter = 5450\n","[('loss', 0.023582780733704567), ('classifier_loss', 0.014881801791489124), ('fe_model_loss', 0.008700978942215443)]\n","313/313 [==============================] - 1s 3ms/step\n","Target acc: 0.355\n","Target mae: 0.1300117\n","iter = 5500\n","[('loss', 0.024964097887277603), ('classifier_loss', 0.016393959522247314), ('fe_model_loss', 0.008570138365030289)]\n","313/313 [==============================] - 1s 3ms/step\n","Target acc: 0.3519\n","Target mae: 0.13040672\n","iter = 5550\n","[('loss', 0.023501228541135788), ('classifier_loss', 0.014822380617260933), ('fe_model_loss', 0.00867884699255228)]\n","313/313 [==============================] - 1s 3ms/step\n","Target acc: 0.3524\n","Target mae: 0.13039523\n","iter = 5600\n","[('loss', 0.034138478338718414), ('classifier_loss', 0.025562619790434837), ('fe_model_loss', 0.008575859479606152)]\n","313/313 [==============================] - 1s 3ms/step\n","Target acc: 0.3495\n","Target mae: 0.13099292\n","iter = 5650\n","[('loss', 0.029559824615716934), ('classifier_loss', 0.02129954844713211), ('fe_model_loss', 0.008260275237262249)]\n","313/313 [==============================] - 1s 3ms/step\n","Target acc: 0.3528\n","Target mae: 0.13049257\n","iter = 5700\n","[('loss', 0.018903221935033798), ('classifier_loss', 0.009835811331868172), ('fe_model_loss', 0.009067411534488201)]\n","313/313 [==============================] - 1s 3ms/step\n","Target acc: 0.351\n","Target mae: 0.13067201\n","iter = 5750\n","[('loss', 0.029030809178948402), ('classifier_loss', 0.020534617826342583), ('fe_model_loss', 0.00849619135260582)]\n","313/313 [==============================] - 1s 3ms/step\n","Target acc: 0.3528\n","Target mae: 0.13046545\n","iter = 5800\n","[('loss', 0.01308115478605032), ('classifier_loss', 0.005036786198616028), ('fe_model_loss', 0.008044368587434292)]\n","313/313 [==============================] - 1s 3ms/step\n","Target acc: 0.3504\n","Target mae: 0.1308779\n","iter = 5850\n","[('loss', 0.050347715616226196), ('classifier_loss', 0.041966602206230164), ('fe_model_loss', 0.008381112478673458)]\n","313/313 [==============================] - 1s 3ms/step\n","Target acc: 0.3548\n","Target mae: 0.13002329\n","iter = 5900\n","[('loss', 0.031042911112308502), ('classifier_loss', 0.022718708962202072), ('fe_model_loss', 0.008324201218783855)]\n","313/313 [==============================] - 1s 3ms/step\n","Target acc: 0.3539\n","Target mae: 0.12995829\n","iter = 5950\n","[('loss', 0.01304883137345314), ('classifier_loss', 0.005013488233089447), ('fe_model_loss', 0.008035343140363693)]\n","313/313 [==============================] - 1s 3ms/step\n","Target acc: 0.3552\n","Target mae: 0.12996325\n","iter = 6000\n","[('loss', 0.0290704146027565), ('classifier_loss', 0.02054879255592823), ('fe_model_loss', 0.00852162204682827)]\n","313/313 [==============================] - 1s 3ms/step\n","Target acc: 0.3518\n","Target mae: 0.1304732\n","iter = 6050\n","[('loss', 0.02205713465809822), ('classifier_loss', 0.01413473580032587), ('fe_model_loss', 0.00792239885777235)]\n","313/313 [==============================] - 1s 3ms/step\n","Target acc: 0.353\n","Target mae: 0.1301845\n","iter = 6100\n","[('loss', 0.014446461573243141), ('classifier_loss', 0.006410257425159216), ('fe_model_loss', 0.008036203682422638)]\n","313/313 [==============================] - 1s 3ms/step\n","Target acc: 0.3558\n","Target mae: 0.1297747\n","iter = 6150\n","[('loss', 0.017067858949303627), ('classifier_loss', 0.009177652187645435), ('fe_model_loss', 0.007890206761658192)]\n","313/313 [==============================] - 1s 3ms/step\n","Target acc: 0.3481\n","Target mae: 0.13097835\n","iter = 6200\n","[('loss', 0.014684903435409069), ('classifier_loss', 0.006325354799628258), ('fe_model_loss', 0.008359548635780811)]\n","313/313 [==============================] - 1s 3ms/step\n","Target acc: 0.3499\n","Target mae: 0.1306818\n","iter = 6250\n","[('loss', 0.029748499393463135), ('classifier_loss', 0.02173732779920101), ('fe_model_loss', 0.008011171594262123)]\n","313/313 [==============================] - 1s 3ms/step\n","Target acc: 0.3504\n","Target mae: 0.13058741\n","iter = 6300\n","[('loss', 0.022011203691363335), ('classifier_loss', 0.014015850611031055), ('fe_model_loss', 0.00799535308033228)]\n","313/313 [==============================] - 1s 3ms/step\n","Target acc: 0.3489\n","Target mae: 0.13087693\n","iter = 6350\n","[('loss', 0.014200223609805107), ('classifier_loss', 0.0059700277633965015), ('fe_model_loss', 0.008230196312069893)]\n","313/313 [==============================] - 1s 3ms/step\n","Target acc: 0.3567\n","Target mae: 0.12950516\n","iter = 6400\n","[('loss', 0.017830923199653625), ('classifier_loss', 0.010005302727222443), ('fe_model_loss', 0.007825620472431183)]\n","313/313 [==============================] - 1s 3ms/step\n","Target acc: 0.3528\n","Target mae: 0.13041031\n","iter = 6450\n","[('loss', 0.01857846975326538), ('classifier_loss', 0.010793481022119522), ('fe_model_loss', 0.007784989196807146)]\n","313/313 [==============================] - 1s 3ms/step\n","Target acc: 0.3524\n","Target mae: 0.13027461\n","iter = 6500\n","[('loss', 0.03586507961153984), ('classifier_loss', 0.027049042284488678), ('fe_model_loss', 0.008816036395728588)]\n","313/313 [==============================] - 1s 3ms/step\n","Target acc: 0.3532\n","Target mae: 0.13026527\n","iter = 6550\n","[('loss', 0.016774151474237442), ('classifier_loss', 0.00803083460777998), ('fe_model_loss', 0.008743316866457462)]\n","313/313 [==============================] - 1s 3ms/step\n","Target acc: 0.3555\n","Target mae: 0.13000514\n","iter = 6600\n","[('loss', 0.026899073272943497), ('classifier_loss', 0.018728798255324364), ('fe_model_loss', 0.008170275948941708)]\n","313/313 [==============================] - 1s 3ms/step\n","Target acc: 0.3511\n","Target mae: 0.1308305\n","iter = 6650\n","[('loss', 0.02705143764615059), ('classifier_loss', 0.01883545145392418), ('fe_model_loss', 0.008215985260903835)]\n","313/313 [==============================] - 1s 3ms/step\n","Target acc: 0.3475\n","Target mae: 0.13129775\n","iter = 6700\n","[('loss', 0.01387052983045578), ('classifier_loss', 0.005781083833426237), ('fe_model_loss', 0.008089445531368256)]\n","313/313 [==============================] - 1s 3ms/step\n","Target acc: 0.3511\n","Target mae: 0.13062266\n","iter = 6750\n","[('loss', 0.020083975046873093), ('classifier_loss', 0.012056723237037659), ('fe_model_loss', 0.00802725087851286)]\n","313/313 [==============================] - 1s 3ms/step\n","Target acc: 0.3526\n","Target mae: 0.13022873\n","iter = 6800\n","[('loss', 0.03636596351861954), ('classifier_loss', 0.028644120320677757), ('fe_model_loss', 0.007721843663603067)]\n","313/313 [==============================] - 1s 3ms/step\n","Target acc: 0.3496\n","Target mae: 0.13078363\n","iter = 6850\n","[('loss', 0.012608367949724197), ('classifier_loss', 0.004660672042518854), ('fe_model_loss', 0.007947695441544056)]\n","313/313 [==============================] - 1s 3ms/step\n","Target acc: 0.3479\n","Target mae: 0.13133964\n","iter = 6900\n","[('loss', 0.05268837884068489), ('classifier_loss', 0.0447237528860569), ('fe_model_loss', 0.007964626885950565)]\n","313/313 [==============================] - 1s 3ms/step\n","Target acc: 0.3489\n","Target mae: 0.13114254\n","iter = 6950\n","[('loss', 0.0346999429166317), ('classifier_loss', 0.02693844586610794), ('fe_model_loss', 0.007761497050523758)]\n","313/313 [==============================] - 1s 3ms/step\n","Target acc: 0.3504\n","Target mae: 0.13066718\n","iter = 7000\n","[('loss', 0.024757198989391327), ('classifier_loss', 0.016806306317448616), ('fe_model_loss', 0.007950892671942711)]\n","313/313 [==============================] - 1s 3ms/step\n","Target acc: 0.3465\n","Target mae: 0.13148026\n","iter = 7050\n","[('loss', 0.026293514296412468), ('classifier_loss', 0.01860780455172062), ('fe_model_loss', 0.0076857092790305614)]\n","313/313 [==============================] - 1s 3ms/step\n","Target acc: 0.3472\n","Target mae: 0.13139631\n","iter = 7100\n","[('loss', 0.04549688100814819), ('classifier_loss', 0.037795063108205795), ('fe_model_loss', 0.007701818365603685)]\n","313/313 [==============================] - 1s 3ms/step\n","Target acc: 0.3495\n","Target mae: 0.1307771\n","iter = 7150\n","[('loss', 0.023214519023895264), ('classifier_loss', 0.01593593694269657), ('fe_model_loss', 0.007278581615537405)]\n","313/313 [==============================] - 1s 3ms/step\n","Target acc: 0.3494\n","Target mae: 0.13093778\n","iter = 7200\n","[('loss', 0.03554840385913849), ('classifier_loss', 0.02797742933034897), ('fe_model_loss', 0.007570974994450808)]\n","313/313 [==============================] - 1s 3ms/step\n","Target acc: 0.3505\n","Target mae: 0.13071044\n","iter = 7250\n","[('loss', 0.011646779254078865), ('classifier_loss', 0.0042160493321716785), ('fe_model_loss', 0.0074307299219071865)]\n","313/313 [==============================] - 1s 3ms/step\n","Target acc: 0.3476\n","Target mae: 0.1312223\n","iter = 7300\n","[('loss', 0.012804940342903137), ('classifier_loss', 0.005537393037229776), ('fe_model_loss', 0.0072675468400120735)]\n","313/313 [==============================] - 1s 3ms/step\n","Target acc: 0.3489\n","Target mae: 0.13104226\n","iter = 7350\n","[('loss', 0.02701648883521557), ('classifier_loss', 0.0194412712007761), ('fe_model_loss', 0.007575217634439468)]\n","313/313 [==============================] - 1s 3ms/step\n","Target acc: 0.3462\n","Target mae: 0.13138245\n","iter = 7400\n","[('loss', 0.04404632747173309), ('classifier_loss', 0.03677283227443695), ('fe_model_loss', 0.007273495197296143)]\n","313/313 [==============================] - 1s 3ms/step\n","Target acc: 0.3494\n","Target mae: 0.1308273\n","iter = 7450\n","[('loss', 0.01130094937980175), ('classifier_loss', 0.00412147119641304), ('fe_model_loss', 0.00717947818338871)]\n","313/313 [==============================] - 1s 3ms/step\n","Target acc: 0.348\n","Target mae: 0.13113277\n","iter = 7500\n","[('loss', 0.0334588922560215), ('classifier_loss', 0.02622450701892376), ('fe_model_loss', 0.007234383840113878)]\n","313/313 [==============================] - 1s 3ms/step\n","Target acc: 0.3462\n","Target mae: 0.13145587\n","iter = 7550\n","[('loss', 0.013002115301787853), ('classifier_loss', 0.00581131037324667), ('fe_model_loss', 0.0071908049285411835)]\n","313/313 [==============================] - 1s 3ms/step\n","Target acc: 0.3493\n","Target mae: 0.1309738\n","iter = 7600\n","[('loss', 0.025116389617323875), ('classifier_loss', 0.017896253615617752), ('fe_model_loss', 0.007220136467367411)]\n","313/313 [==============================] - 1s 3ms/step\n","Target acc: 0.3497\n","Target mae: 0.13104329\n","iter = 7650\n","[('loss', 0.03590467572212219), ('classifier_loss', 0.028852902352809906), ('fe_model_loss', 0.007051774300634861)]\n","313/313 [==============================] - 1s 3ms/step\n","Target acc: 0.3474\n","Target mae: 0.1311429\n","iter = 7700\n","[('loss', 0.010392858646810055), ('classifier_loss', 0.0029617047403007746), ('fe_model_loss', 0.0074311536736786366)]\n","313/313 [==============================] - 1s 3ms/step\n","Target acc: 0.3481\n","Target mae: 0.13117771\n","iter = 7750\n","[('loss', 0.02576100081205368), ('classifier_loss', 0.018539436161518097), ('fe_model_loss', 0.007221565581858158)]\n","313/313 [==============================] - 1s 3ms/step\n","Target acc: 0.3449\n","Target mae: 0.13170335\n","iter = 7800\n","[('loss', 0.02679961547255516), ('classifier_loss', 0.020000407472252846), ('fe_model_loss', 0.006799208000302315)]\n","313/313 [==============================] - 1s 3ms/step\n","Target acc: 0.3493\n","Target mae: 0.1310286\n","iter = 7850\n","[('loss', 0.026460586115717888), ('classifier_loss', 0.01958756148815155), ('fe_model_loss', 0.006873024627566338)]\n","313/313 [==============================] - 1s 3ms/step\n","Target acc: 0.3491\n","Target mae: 0.1308879\n","iter = 7900\n","[('loss', 0.026036757975816727), ('classifier_loss', 0.01909598894417286), ('fe_model_loss', 0.006940769497305155)]\n","313/313 [==============================] - 1s 3ms/step\n","Target acc: 0.3434\n","Target mae: 0.13190258\n","iter = 7950\n","[('loss', 0.013883102685213089), ('classifier_loss', 0.006794265937060118), ('fe_model_loss', 0.007088836748152971)]\n","313/313 [==============================] - 1s 3ms/step\n","Target acc: 0.3451\n","Target mae: 0.13174748\n","iter = 8000\n","[('loss', 0.02498934604227543), ('classifier_loss', 0.017672544345259666), ('fe_model_loss', 0.00731680216267705)]\n","313/313 [==============================] - 1s 3ms/step\n","Target acc: 0.3482\n","Target mae: 0.13112089\n","iter = 8050\n","[('loss', 0.016898009926080704), ('classifier_loss', 0.010097615420818329), ('fe_model_loss', 0.006800394970923662)]\n","313/313 [==============================] - 1s 3ms/step\n","Target acc: 0.3487\n","Target mae: 0.13084005\n","iter = 8100\n","[('loss', 0.011789522133767605), ('classifier_loss', 0.004956377204507589), ('fe_model_loss', 0.0068331449292600155)]\n","313/313 [==============================] - 1s 3ms/step\n","Target acc: 0.3466\n","Target mae: 0.1315597\n","iter = 8150\n","[('loss', 0.034627765417099), ('classifier_loss', 0.0278900396078825), ('fe_model_loss', 0.006737724412232637)]\n","313/313 [==============================] - 1s 3ms/step\n","Target acc: 0.346\n","Target mae: 0.13135579\n","iter = 8200\n","[('loss', 0.03005366399884224), ('classifier_loss', 0.02257884480059147), ('fe_model_loss', 0.007474818266928196)]\n","313/313 [==============================] - 1s 3ms/step\n","Target acc: 0.3467\n","Target mae: 0.13140555\n","iter = 8250\n","[('loss', 0.024570249021053314), ('classifier_loss', 0.01764962449669838), ('fe_model_loss', 0.006920624990016222)]\n","313/313 [==============================] - 1s 3ms/step\n","Target acc: 0.3469\n","Target mae: 0.13133475\n","iter = 8300\n","[('loss', 0.009793933480978012), ('classifier_loss', 0.002969744149595499), ('fe_model_loss', 0.0068241897970438)]\n","313/313 [==============================] - 1s 3ms/step\n","Target acc: 0.3472\n","Target mae: 0.13126138\n","iter = 8350\n","[('loss', 0.010600569657981396), ('classifier_loss', 0.003777873469516635), ('fe_model_loss', 0.006822695955634117)]\n","313/313 [==============================] - 1s 3ms/step\n","Target acc: 0.3461\n","Target mae: 0.13142404\n","iter = 8400\n","[('loss', 0.04013919457793236), ('classifier_loss', 0.033135704696178436), ('fe_model_loss', 0.007003488950431347)]\n","313/313 [==============================] - 1s 3ms/step\n","Target acc: 0.3483\n","Target mae: 0.13106383\n","iter = 8450\n","[('loss', 0.026773817837238312), ('classifier_loss', 0.01952371560037136), ('fe_model_loss', 0.007250103168189526)]\n","313/313 [==============================] - 1s 3ms/step\n","Target acc: 0.3434\n","Target mae: 0.13200095\n","iter = 8500\n","[('loss', 0.017144234851002693), ('classifier_loss', 0.010320872068405151), ('fe_model_loss', 0.0068233623169362545)]\n","313/313 [==============================] - 1s 3ms/step\n","Target acc: 0.3462\n","Target mae: 0.1316146\n","iter = 8550\n","[('loss', 0.008747076615691185), ('classifier_loss', 0.002055392600595951), ('fe_model_loss', 0.006691684015095234)]\n","313/313 [==============================] - 1s 3ms/step\n","Target acc: 0.3475\n","Target mae: 0.13131687\n","iter = 8600\n","[('loss', 0.04907914251089096), ('classifier_loss', 0.04183318465948105), ('fe_model_loss', 0.007245955988764763)]\n","313/313 [==============================] - 1s 3ms/step\n","Target acc: 0.3457\n","Target mae: 0.13172251\n","iter = 8650\n","[('loss', 0.015896230936050415), ('classifier_loss', 0.00891515240073204), ('fe_model_loss', 0.006981079466640949)]\n","313/313 [==============================] - 1s 3ms/step\n","Target acc: 0.346\n","Target mae: 0.13157038\n","iter = 8700\n","[('loss', 0.02447168529033661), ('classifier_loss', 0.01751209795475006), ('fe_model_loss', 0.0069595882669091225)]\n","313/313 [==============================] - 1s 3ms/step\n","Target acc: 0.3453\n","Target mae: 0.13151875\n","iter = 8750\n","[('loss', 0.01452656276524067), ('classifier_loss', 0.007709636818617582), ('fe_model_loss', 0.0068169254809618)]\n","313/313 [==============================] - 1s 3ms/step\n","Target acc: 0.3458\n","Target mae: 0.13154425\n","iter = 8800\n","[('loss', 0.010734066367149353), ('classifier_loss', 0.004051073919981718), ('fe_model_loss', 0.006682992447167635)]\n","313/313 [==============================] - 1s 3ms/step\n","Target acc: 0.3449\n","Target mae: 0.13172328\n","iter = 8850\n","[('loss', 0.010521100834012032), ('classifier_loss', 0.003636075183749199), ('fe_model_loss', 0.006885025650262833)]\n","313/313 [==============================] - 1s 3ms/step\n","Target acc: 0.3443\n","Target mae: 0.13189979\n","iter = 8900\n","[('loss', 0.020008685067296028), ('classifier_loss', 0.013042687438428402), ('fe_model_loss', 0.0069659980945289135)]\n","313/313 [==============================] - 1s 3ms/step\n","Target acc: 0.3471\n","Target mae: 0.13130057\n","iter = 8950\n","[('loss', 0.02286199852824211), ('classifier_loss', 0.0157345999032259), ('fe_model_loss', 0.007127397693693638)]\n","313/313 [==============================] - 1s 3ms/step\n","Target acc: 0.345\n","Target mae: 0.1317868\n","iter = 9000\n","[('loss', 0.03629233315587044), ('classifier_loss', 0.029665088281035423), ('fe_model_loss', 0.006627243477851152)]\n","313/313 [==============================] - 1s 3ms/step\n","Target acc: 0.3421\n","Target mae: 0.13217135\n","iter = 9050\n","[('loss', 0.016919516026973724), ('classifier_loss', 0.010365736670792103), ('fe_model_loss', 0.0065537793561816216)]\n","313/313 [==============================] - 1s 3ms/step\n","Target acc: 0.3426\n","Target mae: 0.13191369\n","iter = 9100\n","[('loss', 0.017864013090729713), ('classifier_loss', 0.011076141148805618), ('fe_model_loss', 0.006787871941924095)]\n","313/313 [==============================] - 1s 3ms/step\n","Target acc: 0.3418\n","Target mae: 0.13222809\n","iter = 9150\n","[('loss', 0.028581000864505768), ('classifier_loss', 0.021704576909542084), ('fe_model_loss', 0.0068764230236411095)]\n","313/313 [==============================] - 1s 3ms/step\n","Target acc: 0.3472\n","Target mae: 0.13120243\n","iter = 9200\n","[('loss', 0.033702634274959564), ('classifier_loss', 0.027268335223197937), ('fe_model_loss', 0.006434297654777765)]\n","313/313 [==============================] - 1s 3ms/step\n","Target acc: 0.3451\n","Target mae: 0.13182451\n","iter = 9250\n","[('loss', 0.01489957608282566), ('classifier_loss', 0.008022483438253403), ('fe_model_loss', 0.006877092178910971)]\n","313/313 [==============================] - 1s 3ms/step\n","Target acc: 0.3434\n","Target mae: 0.13222823\n","iter = 9300\n","[('loss', 0.025241225957870483), ('classifier_loss', 0.018913166597485542), ('fe_model_loss', 0.006328060291707516)]\n","313/313 [==============================] - 1s 3ms/step\n","Target acc: 0.3438\n","Target mae: 0.13196768\n","iter = 9350\n","[('loss', 0.008903821930289268), ('classifier_loss', 0.0025890409015119076), ('fe_model_loss', 0.006314781494438648)]\n","313/313 [==============================] - 1s 3ms/step\n","Target acc: 0.338\n","Target mae: 0.13286404\n","iter = 9400\n","[('loss', 0.018964119255542755), ('classifier_loss', 0.012210560962557793), ('fe_model_loss', 0.006753559224307537)]\n","313/313 [==============================] - 1s 3ms/step\n","Target acc: 0.3443\n","Target mae: 0.13175142\n","iter = 9450\n","[('loss', 0.04213413596153259), ('classifier_loss', 0.035537563264369965), ('fe_model_loss', 0.006596570834517479)]\n","313/313 [==============================] - 1s 3ms/step\n","Target acc: 0.3436\n","Target mae: 0.13185309\n","iter = 9500\n","[('loss', 0.026640936732292175), ('classifier_loss', 0.020016444846987724), ('fe_model_loss', 0.006624491885304451)]\n","313/313 [==============================] - 1s 3ms/step\n","Target acc: 0.3417\n","Target mae: 0.1326841\n","iter = 9550\n","[('loss', 0.02011527121067047), ('classifier_loss', 0.013249151408672333), ('fe_model_loss', 0.006866120733320713)]\n","313/313 [==============================] - 1s 3ms/step\n","Target acc: 0.3442\n","Target mae: 0.13183425\n","iter = 9600\n","[('loss', 0.014323635958135128), ('classifier_loss', 0.007830648683011532), ('fe_model_loss', 0.006492987275123596)]\n","313/313 [==============================] - 1s 3ms/step\n","Target acc: 0.346\n","Target mae: 0.13148703\n","iter = 9650\n","[('loss', 0.014013759791851044), ('classifier_loss', 0.007088294252753258), ('fe_model_loss', 0.006925466004759073)]\n","313/313 [==============================] - 1s 3ms/step\n","Target acc: 0.34\n","Target mae: 0.13249762\n","iter = 9700\n","[('loss', 0.021555637940764427), ('classifier_loss', 0.014630881138145924), ('fe_model_loss', 0.006924756336957216)]\n","313/313 [==============================] - 1s 3ms/step\n","Target acc: 0.345\n","Target mae: 0.13174567\n","iter = 9750\n","[('loss', 0.017378512769937515), ('classifier_loss', 0.01046893373131752), ('fe_model_loss', 0.006909579504281282)]\n","313/313 [==============================] - 1s 3ms/step\n","Target acc: 0.3415\n","Target mae: 0.13218425\n","iter = 9800\n","[('loss', 0.013745687901973724), ('classifier_loss', 0.007309634704142809), ('fe_model_loss', 0.006436053663492203)]\n","313/313 [==============================] - 1s 3ms/step\n","Target acc: 0.3462\n","Target mae: 0.13141656\n","iter = 9850\n","[('loss', 0.02628953754901886), ('classifier_loss', 0.01931813172996044), ('fe_model_loss', 0.006971406750380993)]\n","313/313 [==============================] - 1s 3ms/step\n","Target acc: 0.3422\n","Target mae: 0.13215375\n","iter = 9900\n","[('loss', 0.024753237143158913), ('classifier_loss', 0.01890682615339756), ('fe_model_loss', 0.005846410524100065)]\n","313/313 [==============================] - 1s 3ms/step\n","Target acc: 0.3451\n","Target mae: 0.13183048\n","iter = 9950\n","[('loss', 0.008162112906575203), ('classifier_loss', 0.001849040505476296), ('fe_model_loss', 0.006313072517514229)]\n","313/313 [==============================] - 1s 3ms/step\n","Target acc: 0.3457\n","Target mae: 0.1318227\n","iter = 10000\n","[('loss', 0.012039655819535255), ('classifier_loss', 0.005389735102653503), ('fe_model_loss', 0.006649920716881752)]\n","313/313 [==============================] - 1s 3ms/step\n","Target acc: 0.3444\n","Target mae: 0.1319995\n","iter = 10050\n","[('loss', 0.015803761780261993), ('classifier_loss', 0.009086757898330688), ('fe_model_loss', 0.006717004347592592)]\n","313/313 [==============================] - 1s 3ms/step\n","Target acc: 0.3422\n","Target mae: 0.1321542\n","iter = 10100\n","[('loss', 0.014673946425318718), ('classifier_loss', 0.008705797605216503), ('fe_model_loss', 0.0059681483544409275)]\n","313/313 [==============================] - 1s 3ms/step\n","Target acc: 0.3427\n","Target mae: 0.13196918\n","iter = 10150\n","[('loss', 0.011076726019382477), ('classifier_loss', 0.004804485477507114), ('fe_model_loss', 0.006272240541875362)]\n","313/313 [==============================] - 1s 3ms/step\n","Target acc: 0.3429\n","Target mae: 0.13200438\n","iter = 10200\n","[('loss', 0.013257261365652084), ('classifier_loss', 0.007143722381442785), ('fe_model_loss', 0.006113538518548012)]\n","313/313 [==============================] - 1s 3ms/step\n","Target acc: 0.3422\n","Target mae: 0.13220158\n","iter = 10250\n","[('loss', 0.035109639167785645), ('classifier_loss', 0.028734514489769936), ('fe_model_loss', 0.006375126074999571)]\n","313/313 [==============================] - 1s 3ms/step\n","Target acc: 0.3445\n","Target mae: 0.13184544\n","iter = 10300\n","[('loss', 0.02026836946606636), ('classifier_loss', 0.014142517931759357), ('fe_model_loss', 0.006125851068645716)]\n","313/313 [==============================] - 1s 3ms/step\n","Target acc: 0.3436\n","Target mae: 0.13199076\n","iter = 10350\n","[('loss', 0.009561707265675068), ('classifier_loss', 0.003445992013439536), ('fe_model_loss', 0.0061157154850661755)]\n","313/313 [==============================] - 1s 3ms/step\n","Target acc: 0.3442\n","Target mae: 0.13179359\n","iter = 10400\n","[('loss', 0.008482662960886955), ('classifier_loss', 0.0022164620459079742), ('fe_model_loss', 0.006266200449317694)]\n","313/313 [==============================] - 1s 3ms/step\n","Target acc: 0.3433\n","Target mae: 0.13205865\n","iter = 10450\n","[('loss', 0.04138263314962387), ('classifier_loss', 0.035022519528865814), ('fe_model_loss', 0.006360111758112907)]\n","313/313 [==============================] - 1s 3ms/step\n","Target acc: 0.3411\n","Target mae: 0.13234654\n","iter = 10500\n","[('loss', 0.00892738625407219), ('classifier_loss', 0.0026283657643944025), ('fe_model_loss', 0.006299020256847143)]\n","313/313 [==============================] - 1s 3ms/step\n","Target acc: 0.3451\n","Target mae: 0.13180342\n","iter = 10550\n","[('loss', 0.023999597877264023), ('classifier_loss', 0.01786150597035885), ('fe_model_loss', 0.0061380909755826)]\n","313/313 [==============================] - 1s 3ms/step\n","Target acc: 0.3428\n","Target mae: 0.13203423\n","iter = 10600\n","[('loss', 0.009817388840019703), ('classifier_loss', 0.003597376635298133), ('fe_model_loss', 0.006220011971890926)]\n","313/313 [==============================] - 1s 3ms/step\n","Target acc: 0.3439\n","Target mae: 0.13194838\n","iter = 10650\n","[('loss', 0.019446013495326042), ('classifier_loss', 0.013202547095716), ('fe_model_loss', 0.006243468727916479)]\n","313/313 [==============================] - 1s 3ms/step\n","Target acc: 0.3423\n","Target mae: 0.13208126\n","iter = 10700\n","[('loss', 0.014633245766162872), ('classifier_loss', 0.008275387808680534), ('fe_model_loss', 0.006357857957482338)]\n","313/313 [==============================] - 1s 3ms/step\n","Target acc: 0.3426\n","Target mae: 0.13219993\n","iter = 10750\n","[('loss', 0.02731778845191002), ('classifier_loss', 0.021566178649663925), ('fe_model_loss', 0.005751608870923519)]\n","313/313 [==============================] - 1s 3ms/step\n","Target acc: 0.3437\n","Target mae: 0.13203077\n","iter = 10800\n","[('loss', 0.024963580071926117), ('classifier_loss', 0.018520647659897804), ('fe_model_loss', 0.0064429328776896)]\n","313/313 [==============================] - 1s 3ms/step\n","Target acc: 0.3427\n","Target mae: 0.13211267\n","iter = 10850\n","[('loss', 0.020530633628368378), ('classifier_loss', 0.014779112301766872), ('fe_model_loss', 0.00575152225792408)]\n","313/313 [==============================] - 1s 3ms/step\n","Target acc: 0.3433\n","Target mae: 0.13192013\n","iter = 10900\n","[('loss', 0.016772666946053505), ('classifier_loss', 0.01044913288205862), ('fe_model_loss', 0.0063235340639948845)]\n","313/313 [==============================] - 1s 3ms/step\n","Target acc: 0.3415\n","Target mae: 0.13224223\n","iter = 10950\n","[('loss', 0.011303749866783619), ('classifier_loss', 0.005595758091658354), ('fe_model_loss', 0.005707991775125265)]\n","313/313 [==============================] - 1s 3ms/step\n","Target acc: 0.3443\n","Target mae: 0.1319122\n","iter = 11000\n","[('loss', 0.036241743713617325), ('classifier_loss', 0.029397649690508842), ('fe_model_loss', 0.006844095420092344)]\n","313/313 [==============================] - 1s 3ms/step\n","Target acc: 0.3431\n","Target mae: 0.13201639\n","iter = 11050\n","[('loss', 0.024693090468645096), ('classifier_loss', 0.018495427444577217), ('fe_model_loss', 0.006197662558406591)]\n","313/313 [==============================] - 1s 3ms/step\n","Target acc: 0.3433\n","Target mae: 0.13207458\n","iter = 11100\n","[('loss', 0.011545821093022823), ('classifier_loss', 0.005319977644830942), ('fe_model_loss', 0.006225843448191881)]\n","313/313 [==============================] - 1s 3ms/step\n","Target acc: 0.3437\n","Target mae: 0.13195992\n","iter = 11150\n","[('loss', 0.01840394176542759), ('classifier_loss', 0.01245805062353611), ('fe_model_loss', 0.005945891607552767)]\n","313/313 [==============================] - 1s 3ms/step\n","Target acc: 0.3429\n","Target mae: 0.13205688\n","iter = 11200\n","[('loss', 0.010819679126143456), ('classifier_loss', 0.00537347886711359), ('fe_model_loss', 0.005446200724691153)]\n","313/313 [==============================] - 1s 3ms/step\n","Target acc: 0.3428\n","Target mae: 0.13206375\n","iter = 11250\n","[('loss', 0.0157039612531662), ('classifier_loss', 0.00905945710837841), ('fe_model_loss', 0.006644503679126501)]\n","313/313 [==============================] - 1s 3ms/step\n","Target acc: 0.3419\n","Target mae: 0.13217163\n","iter = 11300\n","[('loss', 0.011897724121809006), ('classifier_loss', 0.006121800281107426), ('fe_model_loss', 0.00577592384070158)]\n","313/313 [==============================] - 1s 3ms/step\n","Target acc: 0.3433\n","Target mae: 0.13204816\n","iter = 11350\n","[('loss', 0.011662252247333527), ('classifier_loss', 0.005457443650811911), ('fe_model_loss', 0.006204808596521616)]\n","313/313 [==============================] - 1s 3ms/step\n","Target acc: 0.3417\n","Target mae: 0.13228032\n","iter = 11400\n","[('loss', 0.016659393906593323), ('classifier_loss', 0.010439945384860039), ('fe_model_loss', 0.006219447590410709)]\n","313/313 [==============================] - 1s 3ms/step\n","Target acc: 0.3424\n","Target mae: 0.13215259\n","iter = 11450\n","[('loss', 0.01255941390991211), ('classifier_loss', 0.0063754296861588955), ('fe_model_loss', 0.006183984223753214)]\n","313/313 [==============================] - 1s 3ms/step\n","Target acc: 0.3431\n","Target mae: 0.13210405\n","iter = 11500\n","[('loss', 0.025548409670591354), ('classifier_loss', 0.019904453307390213), ('fe_model_loss', 0.005643955897539854)]\n","313/313 [==============================] - 1s 3ms/step\n","Target acc: 0.3423\n","Target mae: 0.13222122\n","iter = 11550\n","[('loss', 0.007617599330842495), ('classifier_loss', 0.0018087646458297968), ('fe_model_loss', 0.0058088344521820545)]\n","313/313 [==============================] - 1s 3ms/step\n","Target acc: 0.343\n","Target mae: 0.1320873\n","iter = 11600\n","[('loss', 0.02802972123026848), ('classifier_loss', 0.02214641682803631), ('fe_model_loss', 0.005883304867893457)]\n","313/313 [==============================] - 1s 3ms/step\n","Target acc: 0.3423\n","Target mae: 0.13203189\n","iter = 11650\n","[('loss', 0.01240496151149273), ('classifier_loss', 0.006158004514873028), ('fe_model_loss', 0.006246956996619701)]\n","313/313 [==============================] - 1s 3ms/step\n","Target acc: 0.344\n","Target mae: 0.13195558\n","iter = 11700\n","[('loss', 0.008990239351987839), ('classifier_loss', 0.0031487499363720417), ('fe_model_loss', 0.005841489881277084)]\n","313/313 [==============================] - 1s 3ms/step\n","Target acc: 0.3427\n","Target mae: 0.13202941\n","iter = 11750\n","[('loss', 0.017879292368888855), ('classifier_loss', 0.012061228975653648), ('fe_model_loss', 0.005818062927573919)]\n","313/313 [==============================] - 1s 3ms/step\n","Target acc: 0.3446\n","Target mae: 0.13190147\n","iter = 11800\n","[('loss', 0.011744920164346695), ('classifier_loss', 0.0051455688662827015), ('fe_model_loss', 0.006599350832402706)]\n","313/313 [==============================] - 1s 3ms/step\n","Target acc: 0.3429\n","Target mae: 0.1320882\n","iter = 11850\n","[('loss', 0.007817093282938004), ('classifier_loss', 0.0020470714662224054), ('fe_model_loss', 0.0057700215838849545)]\n","313/313 [==============================] - 1s 3ms/step\n","Target acc: 0.3422\n","Target mae: 0.13217638\n","iter = 11900\n","[('loss', 0.026291176676750183), ('classifier_loss', 0.020526189357042313), ('fe_model_loss', 0.005764986854046583)]\n","313/313 [==============================] - 1s 3ms/step\n","Target acc: 0.3418\n","Target mae: 0.13227054\n","iter = 11950\n","[('loss', 0.02446138486266136), ('classifier_loss', 0.018905743956565857), ('fe_model_loss', 0.005555641371756792)]\n","313/313 [==============================] - 1s 3ms/step\n","Target acc: 0.3444\n","Target mae: 0.13191214\n","iter = 12000\n","[('loss', 0.01268248911947012), ('classifier_loss', 0.0069791232235729694), ('fe_model_loss', 0.00570336589589715)]\n","313/313 [==============================] - 1s 3ms/step\n","Target acc: 0.3431\n","Target mae: 0.13221137\n","iter = 12050\n","[('loss', 0.018160652369260788), ('classifier_loss', 0.012071162462234497), ('fe_model_loss', 0.006089489907026291)]\n","313/313 [==============================] - 1s 3ms/step\n","Target acc: 0.3431\n","Target mae: 0.13205591\n","iter = 12100\n","[('loss', 0.023839032277464867), ('classifier_loss', 0.01826571300625801), ('fe_model_loss', 0.0055733188055455685)]\n","313/313 [==============================] - 1s 3ms/step\n","Target acc: 0.3435\n","Target mae: 0.1320966\n","iter = 12150\n","[('loss', 0.010145431384444237), ('classifier_loss', 0.0045271399430930614), ('fe_model_loss', 0.005618291907012463)]\n","313/313 [==============================] - 1s 3ms/step\n","Target acc: 0.3429\n","Target mae: 0.13216133\n","iter = 12200\n","[('loss', 0.011552154086530209), ('classifier_loss', 0.005406697280704975), ('fe_model_loss', 0.006145458202809095)]\n","313/313 [==============================] - 1s 3ms/step\n","Target acc: 0.3446\n","Target mae: 0.13199893\n","iter = 12250\n","[('loss', 0.020708348602056503), ('classifier_loss', 0.014825187623500824), ('fe_model_loss', 0.005883160047233105)]\n","313/313 [==============================] - 1s 3ms/step\n","Target acc: 0.3436\n","Target mae: 0.13203341\n","iter = 12300\n","[('loss', 0.010422814637422562), ('classifier_loss', 0.004418357275426388), ('fe_model_loss', 0.0060044568963348866)]\n","313/313 [==============================] - 1s 3ms/step\n","Target acc: 0.3424\n","Target mae: 0.13221462\n","iter = 12350\n","[('loss', 0.029819363728165627), ('classifier_loss', 0.02378978207707405), ('fe_model_loss', 0.006029581185430288)]\n","313/313 [==============================] - 1s 3ms/step\n","Target acc: 0.3426\n","Target mae: 0.13220918\n","iter = 12400\n","[('loss', 0.00910726934671402), ('classifier_loss', 0.002957719611003995), ('fe_model_loss', 0.0061495499685406685)]\n","313/313 [==============================] - 1s 3ms/step\n","Target acc: 0.3443\n","Target mae: 0.1318424\n","iter = 12450\n","[('loss', 0.010011532343924046), ('classifier_loss', 0.003858448239043355), ('fe_model_loss', 0.006153084337711334)]\n","313/313 [==============================] - 1s 3ms/step\n","Target acc: 0.341\n","Target mae: 0.13225211\n","iter = 12500\n","[('loss', 0.017528681084513664), ('classifier_loss', 0.011384472250938416), ('fe_model_loss', 0.006144208367913961)]\n","313/313 [==============================] - 1s 3ms/step\n","Target acc: 0.3435\n","Target mae: 0.13206606\n","iter = 12550\n","[('loss', 0.011916322633624077), ('classifier_loss', 0.00597691023722291), ('fe_model_loss', 0.005939412396401167)]\n","313/313 [==============================] - 1s 3ms/step\n","Target acc: 0.3424\n","Target mae: 0.13217528\n","iter = 12600\n","[('loss', 0.010260001756250858), ('classifier_loss', 0.0043202899396419525), ('fe_model_loss', 0.005939711816608906)]\n","313/313 [==============================] - 1s 3ms/step\n","Target acc: 0.3445\n","Target mae: 0.13196287\n","iter = 12650\n","[('loss', 0.016345832496881485), ('classifier_loss', 0.010381108149886131), ('fe_model_loss', 0.005964724812656641)]\n","313/313 [==============================] - 1s 3ms/step\n","Target acc: 0.3424\n","Target mae: 0.13214523\n","iter = 12700\n","[('loss', 0.014080104418098927), ('classifier_loss', 0.008313511498272419), ('fe_model_loss', 0.005766592919826508)]\n","313/313 [==============================] - 1s 3ms/step\n","Target acc: 0.3461\n","Target mae: 0.13164094\n","iter = 12750\n","[('loss', 0.007642359472811222), ('classifier_loss', 0.001995949074625969), ('fe_model_loss', 0.005646410398185253)]\n","313/313 [==============================] - 1s 3ms/step\n","Target acc: 0.3445\n","Target mae: 0.13189347\n","iter = 12800\n","[('loss', 0.00820206105709076), ('classifier_loss', 0.0021994856651872396), ('fe_model_loss', 0.006002574693411589)]\n","313/313 [==============================] - 1s 3ms/step\n","Target acc: 0.3433\n","Target mae: 0.13204658\n","iter = 12850\n","[('loss', 0.027494285255670547), ('classifier_loss', 0.021377118304371834), ('fe_model_loss', 0.006117167882621288)]\n","313/313 [==============================] - 1s 3ms/step\n","Target acc: 0.3454\n","Target mae: 0.1317544\n","iter = 12900\n","[('loss', 0.03693724423646927), ('classifier_loss', 0.03122987225651741), ('fe_model_loss', 0.005707373842597008)]\n","313/313 [==============================] - 1s 3ms/step\n","Target acc: 0.3432\n","Target mae: 0.13209154\n","iter = 12950\n","[('loss', 0.009017450734972954), ('classifier_loss', 0.0034927173983305693), ('fe_model_loss', 0.005524733103811741)]\n","313/313 [==============================] - 1s 3ms/step\n","Target acc: 0.3423\n","Target mae: 0.1322058\n","iter = 13000\n","[('loss', 0.017909366637468338), ('classifier_loss', 0.012211212888360023), ('fe_model_loss', 0.005698153283447027)]\n","313/313 [==============================] - 1s 3ms/step\n","Target acc: 0.3445\n","Target mae: 0.13192311\n","iter = 13050\n","[('loss', 0.02328239008784294), ('classifier_loss', 0.016898809000849724), ('fe_model_loss', 0.006383581552654505)]\n","313/313 [==============================] - 1s 3ms/step\n","Target acc: 0.3416\n","Target mae: 0.13227552\n","iter = 13100\n","[('loss', 0.011078713461756706), ('classifier_loss', 0.0054526072926819324), ('fe_model_loss', 0.005626106169074774)]\n","313/313 [==============================] - 1s 3ms/step\n","Target acc: 0.3422\n","Target mae: 0.13222504\n","iter = 13150\n","[('loss', 0.013587381690740585), ('classifier_loss', 0.007774558383971453), ('fe_model_loss', 0.005812822841107845)]\n","313/313 [==============================] - 1s 3ms/step\n","Target acc: 0.3428\n","Target mae: 0.13216057\n","iter = 13200\n","[('loss', 0.007968981750309467), ('classifier_loss', 0.0025954244192689657), ('fe_model_loss', 0.005373557563871145)]\n","313/313 [==============================] - 1s 3ms/step\n","Target acc: 0.3443\n","Target mae: 0.13201787\n","iter = 13250\n","[('loss', 0.008022971451282501), ('classifier_loss', 0.0019357349956408143), ('fe_model_loss', 0.006087236572057009)]\n","313/313 [==============================] - 1s 3ms/step\n","Target acc: 0.3447\n","Target mae: 0.13175178\n","iter = 13300\n","[('loss', 0.02307376265525818), ('classifier_loss', 0.01691848784685135), ('fe_model_loss', 0.006155275274068117)]\n","313/313 [==============================] - 1s 3ms/step\n","Target acc: 0.3444\n","Target mae: 0.13182217\n","iter = 13350\n","[('loss', 0.02166491001844406), ('classifier_loss', 0.015815317630767822), ('fe_model_loss', 0.005849591456353664)]\n","313/313 [==============================] - 1s 3ms/step\n","Target acc: 0.344\n","Target mae: 0.13198288\n","iter = 13400\n","[('loss', 0.015091178938746452), ('classifier_loss', 0.008938944898545742), ('fe_model_loss', 0.006152233574539423)]\n","313/313 [==============================] - 1s 3ms/step\n","Target acc: 0.3446\n","Target mae: 0.13190149\n","iter = 13450\n","[('loss', 0.03419742360711098), ('classifier_loss', 0.028494780883193016), ('fe_model_loss', 0.005702642723917961)]\n","313/313 [==============================] - 1s 3ms/step\n","Target acc: 0.3446\n","Target mae: 0.13195054\n","iter = 13500\n","[('loss', 0.028116712346673012), ('classifier_loss', 0.021971091628074646), ('fe_model_loss', 0.006145621184259653)]\n","313/313 [==============================] - 1s 3ms/step\n","Target acc: 0.3448\n","Target mae: 0.1320057\n","iter = 13550\n","[('loss', 0.03124360367655754), ('classifier_loss', 0.025449208915233612), ('fe_model_loss', 0.005794393830001354)]\n","313/313 [==============================] - 1s 3ms/step\n","Target acc: 0.3433\n","Target mae: 0.13199529\n","iter = 13600\n","[('loss', 0.022908570244908333), ('classifier_loss', 0.016971370205283165), ('fe_model_loss', 0.005937198176980019)]\n","313/313 [==============================] - 1s 3ms/step\n","Target acc: 0.3439\n","Target mae: 0.13197803\n","iter = 13650\n","[('loss', 0.023622339591383934), ('classifier_loss', 0.017648786306381226), ('fe_model_loss', 0.005973552819341421)]\n","313/313 [==============================] - 1s 3ms/step\n","Target acc: 0.3429\n","Target mae: 0.13216485\n","iter = 13700\n","[('loss', 0.011576766148209572), ('classifier_loss', 0.005796770565211773), ('fe_model_loss', 0.005779996048659086)]\n","313/313 [==============================] - 1s 3ms/step\n","Target acc: 0.3433\n","Target mae: 0.13208672\n","iter = 13750\n","[('loss', 0.015183094888925552), ('classifier_loss', 0.008675651624798775), ('fe_model_loss', 0.00650744279846549)]\n","313/313 [==============================] - 1s 3ms/step\n","Target acc: 0.3456\n","Target mae: 0.13170592\n","iter = 13800\n","[('loss', 0.02015582099556923), ('classifier_loss', 0.013874496333301067), ('fe_model_loss', 0.006281325593590736)]\n","313/313 [==============================] - 1s 3ms/step\n","Target acc: 0.343\n","Target mae: 0.13214584\n","iter = 13850\n","[('loss', 0.025340721011161804), ('classifier_loss', 0.01975206658244133), ('fe_model_loss', 0.005588655825704336)]\n","313/313 [==============================] - 1s 3ms/step\n","Target acc: 0.3442\n","Target mae: 0.1319058\n","iter = 13900\n","[('loss', 0.018319537863135338), ('classifier_loss', 0.012527710758149624), ('fe_model_loss', 0.005791827570647001)]\n","313/313 [==============================] - 1s 3ms/step\n","Target acc: 0.3431\n","Target mae: 0.13214333\n","iter = 13950\n","[('loss', 0.00851207785308361), ('classifier_loss', 0.0029027950949966908), ('fe_model_loss', 0.0056092822924256325)]\n","313/313 [==============================] - 1s 3ms/step\n","Target acc: 0.3419\n","Target mae: 0.13217036\n","iter = 14000\n","[('loss', 0.014072400517761707), ('classifier_loss', 0.008667606860399246), ('fe_model_loss', 0.005404793657362461)]\n","313/313 [==============================] - 1s 3ms/step\n","Target acc: 0.3429\n","Target mae: 0.13203616\n","iter = 14050\n","[('loss', 0.008259369060397148), ('classifier_loss', 0.0028132214210927486), ('fe_model_loss', 0.005446148104965687)]\n","313/313 [==============================] - 1s 3ms/step\n","Target acc: 0.3453\n","Target mae: 0.13179812\n","iter = 14100\n","[('loss', 0.007411580067127943), ('classifier_loss', 0.001802096958272159), ('fe_model_loss', 0.005609482992440462)]\n","313/313 [==============================] - 1s 3ms/step\n","Target acc: 0.3447\n","Target mae: 0.13190499\n","iter = 14150\n","[('loss', 0.016350628808140755), ('classifier_loss', 0.010703518986701965), ('fe_model_loss', 0.0056471070274710655)]\n","313/313 [==============================] - 1s 3ms/step\n","Target acc: 0.3422\n","Target mae: 0.13217308\n","iter = 14200\n","[('loss', 0.013027647510170937), ('classifier_loss', 0.006826614961028099), ('fe_model_loss', 0.006201033014804125)]\n","313/313 [==============================] - 1s 3ms/step\n","Target acc: 0.3413\n","Target mae: 0.13239916\n","iter = 14250\n","[('loss', 0.019855812191963196), ('classifier_loss', 0.014153607189655304), ('fe_model_loss', 0.0057022059336304665)]\n","313/313 [==============================] - 1s 3ms/step\n","Target acc: 0.3425\n","Target mae: 0.13213333\n","iter = 14300\n","[('loss', 0.018651755526661873), ('classifier_loss', 0.012505397200584412), ('fe_model_loss', 0.006146357860416174)]\n","313/313 [==============================] - 1s 3ms/step\n","Target acc: 0.3426\n","Target mae: 0.132186\n","iter = 14350\n","[('loss', 0.016015077009797096), ('classifier_loss', 0.010235760360956192), ('fe_model_loss', 0.0057793171145021915)]\n","313/313 [==============================] - 1s 3ms/step\n","Target acc: 0.3424\n","Target mae: 0.13214329\n","iter = 14400\n","[('loss', 0.016789481043815613), ('classifier_loss', 0.011141658760607243), ('fe_model_loss', 0.005647821817547083)]\n","313/313 [==============================] - 1s 3ms/step\n","Target acc: 0.3421\n","Target mae: 0.13211888\n","iter = 14450\n","[('loss', 0.02109692059457302), ('classifier_loss', 0.015499542467296124), ('fe_model_loss', 0.005597378592938185)]\n","313/313 [==============================] - 1s 3ms/step\n","Target acc: 0.344\n","Target mae: 0.13196477\n","iter = 14500\n","[('loss', 0.010296149179339409), ('classifier_loss', 0.0043880147859454155), ('fe_model_loss', 0.005908134393393993)]\n","313/313 [==============================] - 1s 3ms/step\n","Target acc: 0.3452\n","Target mae: 0.13174307\n","iter = 14550\n","[('loss', 0.017336327582597733), ('classifier_loss', 0.01168492715805769), ('fe_model_loss', 0.005651402287185192)]\n","313/313 [==============================] - 1s 3ms/step\n","Target acc: 0.3423\n","Target mae: 0.13212968\n","iter = 14600\n","[('loss', 0.018908880650997162), ('classifier_loss', 0.013341402634978294), ('fe_model_loss', 0.0055674780160188675)]\n","313/313 [==============================] - 1s 3ms/step\n","Target acc: 0.3448\n","Target mae: 0.13174485\n","iter = 14650\n","[('loss', 0.027251161634922028), ('classifier_loss', 0.020950637757778168), ('fe_model_loss', 0.0063005248084664345)]\n","313/313 [==============================] - 1s 3ms/step\n","Target acc: 0.3418\n","Target mae: 0.13219187\n","iter = 14700\n","[('loss', 0.017415087670087814), ('classifier_loss', 0.011843557469546795), ('fe_model_loss', 0.0055715288035571575)]\n","313/313 [==============================] - 1s 3ms/step\n","Target acc: 0.3417\n","Target mae: 0.13230124\n","iter = 14750\n","[('loss', 0.009211274795234203), ('classifier_loss', 0.0033064489252865314), ('fe_model_loss', 0.005904825869947672)]\n","313/313 [==============================] - 1s 3ms/step\n","Target acc: 0.3436\n","Target mae: 0.13196635\n","iter = 14800\n","[('loss', 0.010243825614452362), ('classifier_loss', 0.0046044597402215), ('fe_model_loss', 0.005639365408569574)]\n","313/313 [==============================] - 1s 3ms/step\n","Target acc: 0.3425\n","Target mae: 0.13221596\n","iter = 14850\n","[('loss', 0.019543534144759178), ('classifier_loss', 0.013753226958215237), ('fe_model_loss', 0.0057903071865439415)]\n","313/313 [==============================] - 1s 3ms/step\n","Target acc: 0.3439\n","Target mae: 0.1320395\n","iter = 14900\n","[('loss', 0.0110316202044487), ('classifier_loss', 0.005052212625741959), ('fe_model_loss', 0.005979408044368029)]\n","313/313 [==============================] - 1s 3ms/step\n","Target acc: 0.3424\n","Target mae: 0.13225746\n","iter = 14950\n","[('loss', 0.011737553402781487), ('classifier_loss', 0.006126295309513807), ('fe_model_loss', 0.005611257627606392)]\n","313/313 [==============================] - 1s 3ms/step\n","Target acc: 0.344\n","Target mae: 0.13191019\n","metrics names: ['acc', 'mae']\n","2290/2290 [==============================] - 6s 3ms/step\n","source train metrics using source+target model (0.9974882946339599, 0.0010124942)\n","1875/1875 [==============================] - 5s 3ms/step\n","target train metrics using source+target model (0.327, 0.13511476)\n","814/814 [==============================] - 2s 3ms/step\n","source test metrics using source+target model (0.9127228027043639, 0.019904306)\n","313/313 [==============================] - 1s 3ms/step\n","target test metrics using source+target model (0.3436, 0.1320322)\n"]}]},{"cell_type":"code","metadata":{"id":"lWKyQbl1UtpY"},"source":["!python deepjdot_demo.py"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"3oFiQDKm5gYm"},"source":["#!tar -xzvf \"/content/deepJDOT/train.tar.gz\" -C \"/content/\" \n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"NjWy6SW16G7B"},"source":["class Deepjdot(object):\n","    def __init__(self, model, batch_size, n_class, optim, allign_loss=1.0, tar_cl_loss=1.0, \n","                 sloss=0.0,tloss=1.0,int_lr=0.01, ot_method='emd',\n","                 jdot_alpha=0.01, lr_decay=True, verbose=1):\n","                     \n","        self.model = model   # target model\n","        self.batch_size = batch_size\n","        self.n_class= n_class\n","        self.optimizer= optim\n","        # initialize the gamma (coupling in OT) with zeros\n","        self.gamma=dnn.K.zeros(shape=(self.batch_size, self.batch_size))\n","        # whether to minimize with classification loss\n","        self.train_cl =dnn.K.variable(tar_cl_loss)\n","        # whether to minimize with the allignment loss \n","        self.train_algn=dnn.K.variable(allign_loss)\n","        self.sloss = dnn.K.variable(sloss) # weight for source classification\n","        self.tloss = dnn.K.variable(tloss) # weight for target classification\n","        self.verbose = verbose\n","        self.int_lr =int_lr  # initial learning rate\n","        self.lr_decay= lr_decay\n","        #\n","        self.ot_method = ot_method\n","        self.jdot_alpha=jdot_alpha  # weight for the alpha term\n","        \n","        \n","        # target classification cross ent loss and source cross entropy\n","        def classifier_cat_loss(y_true, y_pred):\n","            '''\n","            classifier loss based on categorical cross entropy in the target domain\n","            1:batch_size - is source samples\n","            batch_size:end - is target samples\n","            self.gamma - is the optimal transport plan\n","            '''\n","            # source cross entropy loss\n","            ys = y_true[:batch_size,:] # source true labels\n","            ypred_t = y_pred[batch_size:,:] # target prediction\n","            source_ypred = y_pred[:batch_size,:]   # source prediction          \n","            source_loss = dnn.K.mean(dnn.K.categorical_crossentropy(ys, source_ypred))\n","            \n","            # categorical cross entropy loss\n","            ypred_t = dnn.K.log(ypred_t)\n","            # loss calculation based on double sum (sum_ij (ys^i, ypred_t^j))\n","            loss = -dnn.K.dot(ys, dnn.K.transpose(ypred_t))\n","            # returns source loss + target loss\n","            return self.train_cl*(self.tloss*dnn.K.sum(self.gamma * loss) + self.sloss*source_loss)\n","        self.classifier_cat_loss = classifier_cat_loss\n","        \n","        # L2 distance\n","        def L2_dist(x,y):\n","            '''\n","            compute the squared L2 distance between two matrics\n","            '''\n","            dist = dnn.K.reshape(dnn.K.sum(dnn.K.square(x),1), (-1,1))\n","            dist += dnn.K.reshape(dnn.K.sum(dnn.K.square(y),1), (1,-1))\n","            dist -= 2.0*dnn.K.dot(x, dnn.K.transpose(y))  \n","            return dist\n","            \n","       # feature allignment loss\n","        def align_loss(y_true, y_pred):\n","            '''\n","            source and target alignment loss in the intermediate layers of the target model\n","            allignment is performed in the target model (both source and target features are from target model)\n","            y-true - is dummy value( that is full of zeros)\n","            y-pred - is the value of intermediate layers in the target model\n","            1:batch_size - is source samples\n","            batch_size:end - is target samples            \n","            '''\n","            # source domain features            \n","            gs = y_pred[:batch_size,:]\n","            # target domain features\n","            gt = y_pred[batch_size:,:]\n","            gdist = L2_dist(gs,gt)  \n","            return self.jdot_alpha * dnn.K.sum(self.gamma * (gdist))\n","        self.align_loss= align_loss\n","        \n","        def feature_extraction(model, data, out_layer_num=-2):\n","            '''\n","            extract the features from the pre-trained model\n","            inp_layer_num - input layer\n","            out_layer_num -- from which layer to extract the features\n","            '''\n","            intermediate_layer_model = dnn.Model(inputs=model.layers[1].layers[1].input,\n","                             outputs=model.layers[1].layers[out_layer_num].output)\n","            intermediate_output = intermediate_layer_model.predict(data)\n","            return intermediate_output\n","        self.feature_extraction = feature_extraction\n"," \n","\n"," \n","    def fit(self, source_traindata, ys_label, target_traindata, target_label = None,\n","            n_iter=5000, cal_bal=True, sample_size=None):\n","        '''\n","        source_traindata - source domain training data\n","        ys_label - source data true labels\n","        target_traindata - target domain training data\n","        cal_bal - True: source domain samples are equally represented from\n","                        all the classes in the mini-batch (that is, n samples from each class)\n","                - False: source domain samples are randomly sampled\n","        target_label - is not None  : compute the target accuracy over the iterations\n","        '''\n","      \n","        ns = source_traindata.shape[0]\n","        nt= target_traindata.shape[0]\n","        method=self.ot_method # for optimal transport\n","        alpha=self.jdot_alpha\n","        fe_size = self.model.output_shape[1][1]\n","        t_acc = []\n","        t_loss =[]\n","        tloss = dnn.K.eval(self.tloss)\n","        g_metric ='deep' # to allign in intermediate layers, when g_metric='original', the\n","         # alignment loss is performed wrt original input features  (StochJDOT)\n","        \n","        # function to sample n samples from each class\n","        def mini_batch_class_balanced(label, sample_size=20, shuffle=False):\n","            ''' sample the mini-batch with class balanced\n","            '''\n","            label = np.argmax(label, axis=1)\n","            if shuffle:\n","                rindex = np.random.permutation(len(label))\n","                label = label[rindex]\n","\n","            n_class = len(np.unique(label))\n","            index = []\n","            for i in range(n_class):\n","                s_index = np.nonzero(label == i)\n","                s_ind = np.random.permutation(s_index[0])\n","                index = np.append(index, s_ind[0:sample_size])\n","                #          print(index)\n","            index = np.array(index, dtype=int)\n","            return index\n","            \n","         # target model compliation and optimizer\n","        self.model.compile(optimizer= self.optimizer, loss =[self.classifier_cat_loss, self.align_loss])\n","        # set the learning rate\n","        dnn.K.set_value(self.model.optimizer.lr, self.int_lr) \n","        \n","        for i in range(n_iter):\n","            \n","            if self.lr_decay and i > 0 and i%5000 ==0:\n","                # p = float(i) / n_iter\n","                # lr = self.int_lr / (1. + 10 * p)**0.9\n","                lr = dnn.K.get_value(self.model.optimizer.lr)\n","                dnn.K.set_value(self.model.optimizer.lr, lr*0.1)\n","             \n","            # source domain mini-batch indexes\n","            if cal_bal:\n","                s_ind = mini_batch_class_balanced(ys_label, sample_size=sample_size)\n","                self.sbatch_size = len(s_ind)\n","            else:\n","                s_ind = np.random.choice(ns, self.batch_size)\n","                self.sbatch_size = self.batch_size\n","                # target domain mini-batch indexes\n","            t_ind = np.random.choice(nt, self.batch_size)\n","\n","            # source and target domain mini-batch samples \n","            xs_batch, ys = source_traindata[s_ind], ys_label[s_ind]\n","            xt_batch = target_traindata[t_ind]\n","\n","             # dummy target outputs for the keras model\n","            l_dummy = np.zeros_like(ys)  # for target samples\n","               # for intermediate layer feature values in the target model\n","            g_dummy = np.zeros((2*self.batch_size, fe_size)) \n","            s = xs_batch.shape\n","            \n","            # concat of source and target samples and prediction\n","            modelpred = self.model.predict(np.vstack((xs_batch, xt_batch)))\n","           \n","            # modelpred[0] - is softmax prob, and modelpred[1] - is intermediate layer\n","            gs_batch = modelpred[1][:self.batch_size, :]\n","            gt_batch = modelpred[1][self.batch_size:, :]\n","            # softmax prediction of target samples\n","            ft_pred = modelpred[0][self.batch_size:,:]\n","            \n","            \n","            if g_metric=='orginal':\n","                # compution distance metric in the image space\n","                if len(s) == 3:  # when the input is image, convert into 2D matrix\n","                    C0 = cdist(xs_batch.reshape(-1, s[1] * s[2]), xt_batch.reshape(-1,\n","                                                                                   s[1] * s[2]), metric='sqeuclidean')\n","\n","                elif len(s) == 4:\n","                    C0 = cdist(xs_batch.reshape(-1, s[1] * s[2] * s[3]), xt_batch.reshape(-1,                                                                                          s[1] * s[2] * s[3]),metric='sqeuclidean')\n","            else:\n","                # distance computation between source and target in deep layer\n","                C0 = cdist(gs_batch, gt_batch, metric='sqeuclidean')\n","\n","            # ground metric for the target classification loss\n","            C1 = cdist(ys, ft_pred, metric='sqeuclidean')\n","            \n","            # JDOT ground metric\n","            C= alpha*C0+C1\n","                             \n","            # JDOT optimal coupling (gamma)\n","            \n","            if method == 'emd':\n","                 gamma=ot.emd(ot.unif(gs_batch.shape[0]),ot.unif(gt_batch.shape[0]),C)\n","            \n","            # update the computed gamma                      \n","            dnn.K.set_value(self.gamma, gamma)\n","            \n","            # train the keras model on batch\n","            data = np.vstack((xs_batch, xt_batch))    \n","            hist= self.model.train_on_batch([data], [np.vstack((ys,l_dummy)), g_dummy])\n","            \n","            t_loss.append(hist[0])\n","            if self.verbose:\n","                if i%10==0:\n","                   print ('tl_loss ={:f}, fe_loss ={:f},  tot_loss={:f}'.format(hist[1],\n","                          hist[2], hist[0]))\n","                   if target_label is not None:\n","                       tpred = self.model.predict(target_traindata)[0]\n","                       t_acc.append(np.mean(np.argmax(target_label,1)==np.argmax(tpred,1)))\n","                       print('Target acc\\n', t_acc[-1])\n","        return hist, t_loss, t_acc\n","            \n","        \n","\n","    def predict(self, data):\n","        ypred = self.model.predict(data)\n","        return ypred\n","\n","    def evaluate(self, data, label):\n","        ypred = self.model.predict(data)\n","        score = np.mean(np.argmax(label,1)==np.argmax(ypred[0],1))\n","        return score"],"execution_count":null,"outputs":[]}]}